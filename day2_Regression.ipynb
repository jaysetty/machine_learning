{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Continuation with VIF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Examples where VIF is a problem and how to eliminate\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "Let us use the *car-mpg.csv* file containing the cars dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for calculating VIF:\n",
    "\n",
    "* a. Run a multiple regression\n",
    "* b. Calculate the VIF factors\n",
    "* c.  Examine VIF fof each explanatory variable. Consider dropping the variable with VIF more than 5.\n",
    "\n",
    "To construct two design matrices (y and X (outcome and predictor data) we use patsy.dmatrices given a formula_like argument and data. \n",
    "\n",
    "https://etav.github.io/python/vif_factor_python.html\n",
    "\n",
    "https://patsy.readthedocs.io/en/latest/API-reference.html#basic-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas                               as     pd\n",
    "import numpy                                as     np\n",
    "import matplotlib.pyplot                    as     plt\n",
    "import seaborn                              as     sns\n",
    "import statsmodels.api                      as     sm\n",
    "import scipy.stats                          as     stats\n",
    "from   patsy                                import dmatrices\n",
    "from   statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      "mpg         398 non-null float64\n",
      "cyl         398 non-null int64\n",
      "disp        398 non-null float64\n",
      "hp          398 non-null object\n",
      "wt          398 non-null int64\n",
      "acc         398 non-null float64\n",
      "yr          398 non-null int64\n",
      "origin      398 non-null int64\n",
      "car name    398 non-null object\n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "cars = pd.read_csv('./data/car-mpg.csv')\n",
    "cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the predictor variable be stored in X, a Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Collect features\n",
    "\n",
    "features = \"cyl + disp + wt + acc + yr + origin\"\n",
    "\n",
    "### Extract y and X dataframes based on this regression:\n",
    "\n",
    "y, X = dmatrices('mpg ~' + features, cars, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VIF Factor   features\n",
      "0  612.937457  Intercept\n",
      "1   10.541162        cyl\n",
      "2   20.057737       disp\n",
      "3    8.554710         wt\n",
      "4    1.621482        acc\n",
      "5    1.184443         yr\n",
      "6    1.662647     origin\n"
     ]
    }
   ],
   "source": [
    "vif               = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"]   = X.columns\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to retain only one of the highly correlated variables cyl, disp and wt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr coeff between cyl  with mpg is -0.7754\n",
      "Corr coeff between disp with mpg is -0.8042\n",
      "Corr coeff between wt   with mpg is -0.8317\n",
      "\n",
      "We retain the variable highly correlated with target variablea nd drop others\n",
      "We retain wt with -0.8317\n"
     ]
    }
   ],
   "source": [
    "print('Corr coeff between cyl  with mpg is %1.4f'% np.corrcoef(cars.mpg, cars.cyl)[0,1])\n",
    "print('Corr coeff between disp with mpg is %1.4f'% np.corrcoef(cars.mpg, cars.disp)[0,1])\n",
    "print('Corr coeff between wt   with mpg is %1.4f'% np.corrcoef(cars.mpg, cars.wt)[0,1])\n",
    "\n",
    "print('\\nWe retain the variable highly correlated with target variablea nd drop others')\n",
    "print('We retain %s with %1.4f' %('wt',np.corrcoef(cars.mpg, cars.wt)[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After dropping the variables cyl and disp that are least correlated with the target variable, mpg, \n",
    "we run the muliple linear regression model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features =  \"wt + acc + yr + origin\"\n",
    "\n",
    "### Extract y and X dataframes based on this regression:\n",
    "\n",
    "y, X = dmatrices('mpg ~' + features, cars, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VIF Factor   features\n",
      "0  570.081190  Intercept\n",
      "1    1.808820         wt\n",
      "2    1.257330        acc\n",
      "3    1.143102         yr\n",
      "4    1.513603     origin\n"
     ]
    }
   ],
   "source": [
    "vif1               = pd.DataFrame()\n",
    "vif1[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif1[\"features\"]   = X.columns\n",
    "print(vif1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "We don't observe any multi-collinearity in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  In class lab : Practice Exercise 1\n",
    "\n",
    "For *Boston House Prices dataset*, check if there is multi-collinearity and if so remove it.\n",
    "Your target variable is MEDV = Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from   sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect and remove Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we try to get the outliers using IQR by doing the following:\n",
    "* Calculate interquartile range\n",
    "* Calculate the outlier cutoff\n",
    "* Identify outliers (data lying beyond the outlier cutoff\n",
    "* Remove those outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_mark_outliers(data):\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    q25, q75  = np.percentile(data, 25), np.percentile(data, 75)\n",
    "    iqr       = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "    for i in range(len(data)):\n",
    "        x    = data[i]\n",
    "        if x < lower or x > upper:\n",
    "            data[i] = np.NaN  # Mark outliers as NA\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: mpg\n",
      "Percentiles: 25th=17.500, 75th=29.000, IQR=11.500\n",
      "Variable: wt\n",
      "Percentiles: 25th=2223.750, 75th=3608.000, IQR=1384.250\n",
      "Variable: acc\n",
      "Percentiles: 25th=13.825, 75th=17.175, IQR=3.350\n",
      "Variable: yr\n",
      "Percentiles: 25th=73.000, 75th=79.000, IQR=6.000\n",
      "Variable: origin\n",
      "Percentiles: 25th=1.000, 75th=2.000, IQR=1.000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 5 columns):\n",
      "mpg       397 non-null float64\n",
      "wt        398 non-null int64\n",
      "acc       389 non-null float64\n",
      "yr        398 non-null int64\n",
      "origin    398 non-null int64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 15.6 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df      = cars[[ 'mpg', 'wt', 'acc', 'yr', 'origin']]\n",
    "\n",
    "for i in range(len(df.columns)):\n",
    "    data              = df[df.columns[i]]\n",
    "    print('Variable: %s'%df.columns[i])\n",
    "    df[df.columns[i]] = detect_mark_outliers(data)\n",
    "    \n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace = True) ## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(388, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(388, 4)\n",
      "(388,)\n"
     ]
    }
   ],
   "source": [
    "X = df[['wt', 'acc', 'yr', 'origin']]\n",
    "y = df.mpg\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Improving the model with transformation showing R-square, adj R-square\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Boston data set as shown in Practice Exercise 1.\n",
    "Check if the model measures such as R-square and adjusted R square have improved after transforming the predictor variables.\n",
    "Here our target variable is MEDV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas                               as     pd\n",
    "import numpy                                as     np\n",
    "import matplotlib.pyplot                    as     plt\n",
    "import seaborn                              as     sns\n",
    "import statsmodels.api                      as     sm\n",
    "import scipy.stats                          as     stats\n",
    "from   sklearn                              import datasets\n",
    "from   sklearn.metrics                      import mean_squared_error\n",
    "from   sklearn.preprocessing                import PolynomialFeatures\n",
    "from   sklearn.linear_model                 import LinearRegression\n",
    "from   sklearn                              import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "boston = datasets.load_boston()\n",
    "print(boston.data.shape, boston.target.shape)\n",
    "print(boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "data = pd.concat([data, pd.Series(boston.target, name = 'MEDV')], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 01 Dec 2018</td> <th>  Prob (F-statistic):</th> <td>6.95e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:15:42</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   36.4911</td> <td>    5.104</td> <td>    7.149</td> <td> 0.000</td> <td>   26.462</td> <td>   46.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1072</td> <td>    0.033</td> <td>   -3.276</td> <td> 0.001</td> <td>   -0.171</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0464</td> <td>    0.014</td> <td>    3.380</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0209</td> <td>    0.061</td> <td>    0.339</td> <td> 0.735</td> <td>   -0.100</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    2.6886</td> <td>    0.862</td> <td>    3.120</td> <td> 0.002</td> <td>    0.996</td> <td>    4.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  -17.7958</td> <td>    3.821</td> <td>   -4.658</td> <td> 0.000</td> <td>  -25.302</td> <td>  -10.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    3.8048</td> <td>    0.418</td> <td>    9.102</td> <td> 0.000</td> <td>    2.983</td> <td>    4.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0008</td> <td>    0.013</td> <td>    0.057</td> <td> 0.955</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -1.4758</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.868</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.3057</td> <td>    0.066</td> <td>    4.608</td> <td> 0.000</td> <td>    0.175</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0123</td> <td>    0.004</td> <td>   -3.278</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.9535</td> <td>    0.131</td> <td>   -7.287</td> <td> 0.000</td> <td>   -1.211</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0094</td> <td>    0.003</td> <td>    3.500</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.5255</td> <td>    0.051</td> <td>  -10.366</td> <td> 0.000</td> <td>   -0.625</td> <td>   -0.426</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.029</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 782.015</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>1.54e-170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.276</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Sat, 01 Dec 2018   Prob (F-statistic):          6.95e-135\n",
       "Time:                        17:15:42   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.4911      5.104      7.149      0.000      26.462      46.520\n",
       "x1            -0.1072      0.033     -3.276      0.001      -0.171      -0.043\n",
       "x2             0.0464      0.014      3.380      0.001       0.019       0.073\n",
       "x3             0.0209      0.061      0.339      0.735      -0.100       0.142\n",
       "x4             2.6886      0.862      3.120      0.002       0.996       4.381\n",
       "x5           -17.7958      3.821     -4.658      0.000     -25.302     -10.289\n",
       "x6             3.8048      0.418      9.102      0.000       2.983       4.626\n",
       "x7             0.0008      0.013      0.057      0.955      -0.025       0.027\n",
       "x8            -1.4758      0.199     -7.398      0.000      -1.868      -1.084\n",
       "x9             0.3057      0.066      4.608      0.000       0.175       0.436\n",
       "x10           -0.0123      0.004     -3.278      0.001      -0.020      -0.005\n",
       "x11           -0.9535      0.131     -7.287      0.000      -1.211      -0.696\n",
       "x12            0.0094      0.003      3.500      0.001       0.004       0.015\n",
       "x13           -0.5255      0.051    -10.366      0.000      -0.625      -0.426\n",
       "==============================================================================\n",
       "Omnibus:                      178.029   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              782.015\n",
       "Skew:                           1.521   Prob(JB):                    1.54e-170\n",
       "Kurtosis:                       8.276   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X              =  boston.data\n",
    "y              =  boston.target\n",
    "\n",
    "X              = sm.add_constant(X) \n",
    "model          = sm.OLS(y, X).fit()\n",
    "residuals      = model.resid\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try transformation to predictor variables and check coefficient of determination has improved from 0.741."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Model of degree 2 - R square is 0.90 R adj square 0.87\n"
     ]
    }
   ],
   "source": [
    "poly      = PolynomialFeatures(degree=2)\n",
    "X_        = poly.fit_transform(X)\n",
    "\n",
    "model2     = linear_model.LinearRegression()\n",
    "model2.fit(X_, y)\n",
    "\n",
    "r_squared  = model2.score(X_,y)\n",
    "adjusted_r_squared = 1 - (1 - r_squared) * (len(y) - 1) / (len(y) - X_.shape[1] - 1)\n",
    "\n",
    "print('Polynomial Model of degree 2 - R square is %.2f R adj square %.2f' %(r_squared, adjusted_r_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So transformation has improved the earlier model as per details given below:\n",
    "\n",
    "| Model | $R^2$ | Adj $R^2$ |\n",
    "| -------------- | ----- | ------- |  \n",
    "| Linear | 0.741 | 0.734 |\n",
    "| Polynomial | 0.90 | 0.0.87 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://acadgild.com/blog/polynomial-regression-understand-power-of-polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  In class lab : Practice Exercise 2\n",
    "\n",
    "Use the red wine data and predict the target variable, wine quality using the predictor variables (1 to 11).\n",
    "Check whether the transformation of predictor variables has improved R square and adj. R square.\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Input variables (based on physicochemical tests): \n",
    "\n",
    "+ 1 - fixed acidity \n",
    "+ 2 - volatile acidity \n",
    "+ 3 - citric acid \n",
    "+ 4 - residual sugar \n",
    "+ 5 - chlorides \n",
    "+ 6 - free sulfur dioxide \n",
    "+ 7 - total sulfur dioxide \n",
    "+ 8 - density \n",
    "+ 9 - pH \n",
    "+ 10 - sulphates \n",
    "+ 11 - alcohol \n",
    "\n",
    "**Output variable (based on sensory data): **\n",
    "\n",
    "+ 12 - quality (score between 0 and 10)\n",
    "\n",
    "##### Relevant Papers:\n",
    "+ P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. \n",
    "+ In Decision Support Systems, Elsevier, 47(4):547-553, 2009. \n",
    "\n",
    "\n",
    "#### Citation Request:\n",
    "\n",
    "Please include this citation if you plan to use this database: \n",
    "\n",
    "+ P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
    "+ Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1599 non-null float64\n",
      "volatile acidity        1599 non-null float64\n",
      "citric acid             1599 non-null float64\n",
      "residual sugar          1599 non-null float64\n",
      "chlorides               1599 non-null float64\n",
      "free sulfur dioxide     1599 non-null float64\n",
      "total sulfur dioxide    1599 non-null float64\n",
      "density                 1599 non-null float64\n",
      "pH                      1599 non-null float64\n",
      "sulphates               1599 non-null float64\n",
      "alcohol                 1599 non-null float64\n",
      "quality                 1599 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "None\n",
      "(1599, 12)\n",
      "                            0        1       2       3        4\n",
      "fixed acidity          7.4000   7.8000   7.800  11.200   7.4000\n",
      "volatile acidity       0.7000   0.8800   0.760   0.280   0.7000\n",
      "citric acid            0.0000   0.0000   0.040   0.560   0.0000\n",
      "residual sugar         1.9000   2.6000   2.300   1.900   1.9000\n",
      "chlorides              0.0760   0.0980   0.092   0.075   0.0760\n",
      "free sulfur dioxide   11.0000  25.0000  15.000  17.000  11.0000\n",
      "total sulfur dioxide  34.0000  67.0000  54.000  60.000  34.0000\n",
      "density                0.9978   0.9968   0.997   0.998   0.9978\n",
      "pH                     3.5100   3.2000   3.260   3.160   3.5100\n",
      "sulphates              0.5600   0.6800   0.650   0.580   0.5600\n",
      "alcohol                9.4000   9.8000   9.800   9.800   9.4000\n",
      "quality                5.0000   5.0000   5.000   6.000   5.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wine_data   = pd.read_csv('./data/winequality-red.csv', header = 0, sep = ';')\n",
    "print(wine_data.info())\n",
    "print(wine_data.shape)\n",
    "print(wine_data.head(5).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Binary & Multinomial Predictors\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://songhuiming.github.io/pages/2017/01/21/linear-regression-in-python-chapter-3-regression-with-categorical-predictors/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a) Dummy variable\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 370000 used cars scraped with Scrapy from Ebay-Kleinanzeigen. \n",
    "https://www.kaggle.com/orgesleka/used-cars-database/home\n",
    "\n",
    "Those fields are included: autos.csv:\n",
    "\n",
    "| Sl No | Variable | Description | \n",
    "| --- | -------------- | ------------------------------------ |\n",
    "| 1 | dateCrawled | when this ad was first crawled, all field-values are taken from this date | \n",
    "| 2 |  name |  \"name\" of the car | \n",
    "| 3 |  seller | private or dealer | \n",
    "| 4 |  offerType |  | \n",
    "| 5 |  price  |  the price on the ad to sell the car | \n",
    "| 6 |  abtest |  | \n",
    "| 7 |  vehicleType |  | \n",
    "| 8 |  yearOfRegistration |  at which year the car was first registered |  \n",
    "| 9 |  gearbox |  | \n",
    "| 10 |  powerPS  |  power of the car in PS | \n",
    "| 11 |  model |  | \n",
    "| 12 |  kilometer  |  how many kilometers the car has driven | \n",
    "| 13 |  monthOfRegistration  |  at which month the car was first registered | \n",
    "| 14 |  fuelType |  | \n",
    "| 15 |  brand |  | \n",
    "| 16 |  notRepairedDamage  |  if the car has a damage which is not repaired yet | \n",
    "| 17 |  dateCreated  |  the date for which the ad at ebay was created | \n",
    "| 18 |  nrOfPictures  | number of pictures in the ad (unfortunately this field contains everywhere a 0 and is thus useless (bug in crawler!) ) | \n",
    "| 19 |  postalCode  |  | \n",
    "| 20 |  lastSeenOnline |  when the crawler saw this ad last online | \n",
    "\n",
    "The fields lastSeen and dateCreated could be used to estimate how long a car will be at least online before it is sold.\n",
    "## Data brought to you by Orges Leka.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall use the following variables out of 20 variables and also select data with price not more than 50000.\n",
    "1. seller, the nature of seller\n",
    "2. price, the auction price\n",
    "3. yearOfRegistration, the year on which the car was registered first\n",
    "4. gearbox, type of gearbox\n",
    "5. kilometer, number of kilometers\n",
    "6. fuelType, type of fuel (and if the vehicle is electric or not)\n",
    "7. notRepaiedDamage, whether or not the vehicle has damages and has been repaired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas          as pd\n",
    "import numpy           as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 276025 entries, 1 to 371823\n",
      "Data columns (total 7 columns):\n",
      "seller                276025 non-null object\n",
      "price                 276025 non-null int64\n",
      "yearOfRegistration    276025 non-null int64\n",
      "gearbox               276025 non-null object\n",
      "kilometer             276025 non-null int64\n",
      "fuelType              276025 non-null object\n",
      "notRepairedDamage     276025 non-null object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 16.8+ MB\n",
      "None\n",
      "Index(['seller', 'price', 'yearOfRegistration', 'gearbox', 'kilometer',\n",
      "       'fuelType', 'notRepairedDamage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/autos.csv', encoding = 'latin', quoting = 3, usecols = ['seller','price','yearOfRegistration','gearbox','kilometer','fuelType','notRepairedDamage'])\n",
    "data = data[data.price < 50001] # select price <= 50000\n",
    "data.dropna(inplace = True) # Drop Missing values\n",
    "print(data.info())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create X as a vector of predictor variables and y as the response variable vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276025, 6)\n",
      "(276025,)\n"
     ]
    }
   ],
   "source": [
    "X = data[['seller', 'yearOfRegistration', 'gearbox', 'kilometer','fuelType', 'notRepairedDamage']]\n",
    "y = data['price']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the levels of the variables:\n",
    "* 1) gearbox  which is a binary \n",
    "* 2) fuelType, which is multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'automatik', 1: 'manuell'}\n",
      "{0: 'andere', 1: 'benzin', 2: 'cng', 3: 'diesel', 4: 'elektro', 5: 'hybrid', 6: 'lpg'}\n"
     ]
    }
   ],
   "source": [
    "data[\"gearbox\"] = data[\"gearbox\"].astype('category')\n",
    "print(dict( enumerate(data.gearbox.cat.categories)))\n",
    "data[\"fuelType\"] = data[\"fuelType\"].astype('category')\n",
    "print(dict( enumerate(data.fuelType.cat.categories)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "* 1) There are two levels for the variable, gearbox: *automatik and manuell*.\n",
    "* 2) There are seven levels for the variable, fuelType: *andere, benzin,cng,diesel,elektro,hybrid and lpg*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create dummy variables for each of the categorical variables\n",
    "\n",
    "for variable in X.columns:\n",
    "    if X[variable].dtype == object:\n",
    "       dcols = pd.get_dummies(X[variable])\n",
    "       X       = X.join(dcols)\n",
    "       del X[variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   yearOfRegistration  kilometer  gewerblich  privat  automatik  manuell  \\\n",
      "1                2011     125000           0       1          0        1   \n",
      "3                2001     150000           0       1          0        1   \n",
      "4                2008      90000           0       1          0        1   \n",
      "5                1995     150000           0       1          0        1   \n",
      "6                2004     150000           0       1          0        1   \n",
      "\n",
      "   andere  benzin  cng  diesel  elektro  hybrid  lpg  ja  nein  \n",
      "1       0       0    0       1        0       0    0   1     0  \n",
      "3       0       1    0       0        0       0    0   0     1  \n",
      "4       0       0    0       1        0       0    0   0     1  \n",
      "5       0       1    0       0        0       0    0   1     0  \n",
      "6       0       1    0       0        0       0    0   0     1  \n"
     ]
    }
   ],
   "source": [
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.405</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.404</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.705e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 01 Dec 2018</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:15:44</td>     <th>  Log-Likelihood:    </th> <td>-2.7665e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>276025</td>      <th>  AIC:               </th>  <td>5.533e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>276013</td>      <th>  BIC:               </th>  <td>5.533e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>-3043.5557</td> <td>  791.631</td> <td>   -3.845</td> <td> 0.000</td> <td>-4595.130</td> <td>-1491.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearOfRegistration</th> <td>   10.5436</td> <td>    0.400</td> <td>   26.369</td> <td> 0.000</td> <td>    9.760</td> <td>   11.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kilometer</th>          <td>   -0.0831</td> <td>    0.000</td> <td> -310.428</td> <td> 0.000</td> <td>   -0.084</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gewerblich</th>         <td>-3275.0485</td> <td> 2297.565</td> <td>   -1.425</td> <td> 0.154</td> <td>-7778.214</td> <td> 1228.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>privat</th>             <td>  231.4928</td> <td> 1571.037</td> <td>    0.147</td> <td> 0.883</td> <td>-2847.698</td> <td> 3310.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>automatik</th>          <td>  709.8405</td> <td>  396.023</td> <td>    1.792</td> <td> 0.073</td> <td>  -66.354</td> <td> 1486.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>manuell</th>            <td>-3753.3962</td> <td>  396.007</td> <td>   -9.478</td> <td> 0.000</td> <td>-4529.559</td> <td>-2977.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>andere</th>             <td>-4244.3640</td> <td>  489.064</td> <td>   -8.679</td> <td> 0.000</td> <td>-5202.916</td> <td>-3285.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>benzin</th>             <td>   95.5883</td> <td>  170.177</td> <td>    0.562</td> <td> 0.574</td> <td> -237.953</td> <td>  429.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cng</th>                <td>  901.6695</td> <td>  268.247</td> <td>    3.361</td> <td> 0.001</td> <td>  375.913</td> <td> 1427.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>diesel</th>             <td> 4029.0504</td> <td>  171.062</td> <td>   23.553</td> <td> 0.000</td> <td> 3693.773</td> <td> 4364.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>elektro</th>            <td>-6094.3164</td> <td>  571.285</td> <td>  -10.668</td> <td> 0.000</td> <td>-7214.019</td> <td>-4974.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hybrid</th>             <td> 1677.0442</td> <td>  339.890</td> <td>    4.934</td> <td> 0.000</td> <td> 1010.869</td> <td> 2343.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lpg</th>                <td>  591.7725</td> <td>  184.241</td> <td>    3.212</td> <td> 0.001</td> <td>  230.664</td> <td>  952.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ja</th>                 <td>-2983.5059</td> <td>  396.196</td> <td>   -7.530</td> <td> 0.000</td> <td>-3760.040</td> <td>-2206.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nein</th>               <td>  -60.0498</td> <td>  396.122</td> <td>   -0.152</td> <td> 0.880</td> <td> -836.438</td> <td>  716.339</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>104523.624</td> <th>  Durbin-Watson:     </th>  <td>   2.004</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>794297.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 1.630</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>10.644</td>   <th>  Cond. No.          </th>  <td>1.97e+22</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.22e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.405\n",
       "Model:                            OLS   Adj. R-squared:                  0.404\n",
       "Method:                 Least Squares   F-statistic:                 1.705e+04\n",
       "Date:                Sat, 01 Dec 2018   Prob (F-statistic):               0.00\n",
       "Time:                        17:15:44   Log-Likelihood:            -2.7665e+06\n",
       "No. Observations:              276025   AIC:                         5.533e+06\n",
       "Df Residuals:                  276013   BIC:                         5.533e+06\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const              -3043.5557    791.631     -3.845      0.000   -4595.130   -1491.981\n",
       "yearOfRegistration    10.5436      0.400     26.369      0.000       9.760      11.327\n",
       "kilometer             -0.0831      0.000   -310.428      0.000      -0.084      -0.083\n",
       "gewerblich         -3275.0485   2297.565     -1.425      0.154   -7778.214    1228.116\n",
       "privat               231.4928   1571.037      0.147      0.883   -2847.698    3310.683\n",
       "automatik            709.8405    396.023      1.792      0.073     -66.354    1486.035\n",
       "manuell            -3753.3962    396.007     -9.478      0.000   -4529.559   -2977.233\n",
       "andere             -4244.3640    489.064     -8.679      0.000   -5202.916   -3285.812\n",
       "benzin                95.5883    170.177      0.562      0.574    -237.953     429.130\n",
       "cng                  901.6695    268.247      3.361      0.001     375.913    1427.426\n",
       "diesel              4029.0504    171.062     23.553      0.000    3693.773    4364.328\n",
       "elektro            -6094.3164    571.285    -10.668      0.000   -7214.019   -4974.614\n",
       "hybrid              1677.0442    339.890      4.934      0.000    1010.869    2343.220\n",
       "lpg                  591.7725    184.241      3.212      0.001     230.664     952.881\n",
       "ja                 -2983.5059    396.196     -7.530      0.000   -3760.040   -2206.972\n",
       "nein                 -60.0498    396.122     -0.152      0.880    -836.438     716.339\n",
       "==============================================================================\n",
       "Omnibus:                   104523.624   Durbin-Watson:                   2.004\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           794297.077\n",
       "Skew:                           1.630   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.644   Cond. No.                     1.97e+22\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.22e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X              = sm.add_constant(X) \n",
    "model          = sm.OLS(y, X).fit()\n",
    "residuals      = model.resid\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b) Interpretaion of regression coefficients\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our regression equation is given below:\n",
    "\n",
    "price = -3043.5557 + yearOfRegistration * 10.5436  - kilometer * 0.0831 - gewerblich * 3275.0485 + privat * 231.4928 + automatik * 709.8405 - manuell * 3753.3962 - andere * 4244.3640 + benzin * 95.5883 + cng * 901.6695 + diesel * 4029.0504 - elektro * 6094.3164 + hybrid * 1677.0442 + lpg * 591.7725 - ja * 2983.5059 - nein * 60.0498"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to interpret the coefficients for the variable, gearbox which is split into two dummy variables:\n",
    "**automatik and manuell.**\n",
    "\n",
    "Interpretaion of regression coefficients for the \n",
    "\n",
    "Holding all other variables constant, binary variable **gearbox**\n",
    "* a unit increase in automatik (gearbox type) of car will increase the price by 709.8405.\n",
    "* a unit increase in manuell (gearbox type) of car will decrease the price by 3753.3962.\n",
    "\n",
    "Holding all other variables constant, multinomial variable **fuelType**\n",
    "* a unit increase in andere(fuelType) of car will decrease the price by 4244.36.\n",
    "* a unit increase in benzin(fuelType) of car will increase the price by 95.59.\n",
    "* a unit increase in cng(fuelType) of car will increase the price by 901.67.\n",
    "* a unit increase in diesel(fuelType) of car will increase the price by 4029.05.\n",
    "* a unit increase in elektro(fuelType) of car will decrease the price by 6094.32.\n",
    "* a unit increase in hybrid(fuelType) of car will increase the price by 1677.04.\n",
    "* a unit increase in lpg(fuelType) of car will increase the price by 591.77."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c) Interaction effects\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the price of car increase more with kilometer and automatic gearbox than manuell gearbox?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.413\n",
      "Model:                            OLS   Adj. R-squared:                  0.413\n",
      "Method:                 Least Squares   F-statistic:                 1.620e+04\n",
      "Date:                Sat, 01 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                        17:15:47   Log-Likelihood:            -2.7645e+06\n",
      "No. Observations:              276025   AIC:                         5.529e+06\n",
      "Df Residuals:                  276012   BIC:                         5.529e+06\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                        -1.02e+04   3944.501     -2.587      0.010   -1.79e+04   -2472.525\n",
      "C(seller)[T.privat]              4373.3836   3827.702      1.143      0.253   -3128.808    1.19e+04\n",
      "C(gearbox)[T.manuell]           -9180.3935     78.019   -117.669      0.000   -9333.308   -9027.479\n",
      "C(fuelType)[T.benzin]            4113.1424    533.618      7.708      0.000    3067.266    5159.019\n",
      "C(fuelType)[T.cng]               4937.6782    585.278      8.436      0.000    3790.549    6084.807\n",
      "C(fuelType)[T.diesel]            8045.1694    533.851     15.070      0.000    6998.836    9091.502\n",
      "C(fuelType)[T.elektro]          -4339.9506    829.340     -5.233      0.000   -5965.434   -2714.467\n",
      "C(fuelType)[T.hybrid]            4686.3983    633.963      7.392      0.000    3443.848    5928.948\n",
      "C(fuelType)[T.lpg]               4769.4119    539.881      8.834      0.000    3711.260    5827.564\n",
      "C(notRepairedDamage)[T.nein]     2939.0787     32.767     89.697      0.000    2874.857    3003.301\n",
      "yearOfRegistration                 10.6574      0.397     26.849      0.000       9.879      11.435\n",
      "kilometer                          -0.1119      0.001   -213.620      0.000      -0.113      -0.111\n",
      "kilometer:C(gearbox)[T.manuell]     0.0384      0.001     63.818      0.000       0.037       0.040\n",
      "==============================================================================\n",
      "Omnibus:                   101492.027   Durbin-Watson:                   2.004\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           805199.271\n",
      "Skew:                           1.560   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.764   Cond. No.                     8.95e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.95e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "result = ols(formula = 'price ~ C(seller) + yearOfRegistration + C(gearbox) + kilometer + C(fuelType) + C(notRepairedDamage) + kilometer * C(gearbox)', data = data).fit()    \n",
    "print(result.summary())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "From the above coefficients table,.we observe that holding all other variables constant, a unit increase in kilometer and when the gearbox is manaul, the price increases by 0.0384."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  In class lab : Practice Exercise 3\n",
    "\n",
    "Use Carseats.csv, a simulated data set containing sales of child car seats at 400 different stores.\n",
    "\n",
    "Predict Sales using the explanatory variables 2 to 10 listed below and interpret the coefficients:\n",
    "\n",
    "Format A data frame with 400 observations on the following 11 variables.\n",
    "\n",
    "| Sl No | Variable | Description |\n",
    "| --- | ------------------- | --------------------------------- |\n",
    "| 1 | Sales | Unit sales (in thousands) at each location  | \n",
    "| 2 | CompPrice | Price charged by competitor at each location | \n",
    "| 3 | Income | Community income level (in thousands of dollars) | \n",
    "| 4 | Advertising | Local advertising budget for company at each location (in thousands of dollars)  | \n",
    "| 5 | Population | Population size in region (in thousands) | \n",
    "| 6 | Price | Price company charges for car seats at each site | \n",
    "| 7 | ShelveLoc | A factor with levels Bad, Good and Medium indicating the quality of the shelving location for the car seats at each site |  \n",
    "| 8 | Age | Average age of the local population | \n",
    "| 9 | Education | Education level at each location | \n",
    "| 10 | Urban | A factor with levels No and Yes to indicate whether the store is in an urban or rural location | \n",
    "| 11 | US | A factor with levels No and Yes to indicate whether the store is in the US or not | \n",
    "\n",
    "** Source Simulated data** \n",
    "\n",
    "References James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) An Introduction to Statistical Learning with applications in R, www.StatLearning.com, Springer-Verlag, New York\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 11 columns):\n",
      "Sales          400 non-null float64\n",
      "CompPrice      400 non-null int64\n",
      "Income         400 non-null int64\n",
      "Advertising    400 non-null int64\n",
      "Population     400 non-null int64\n",
      "Price          400 non-null int64\n",
      "ShelveLoc      400 non-null object\n",
      "Age            400 non-null int64\n",
      "Education      400 non-null int64\n",
      "Urban          400 non-null object\n",
      "US             400 non-null object\n",
      "dtypes: float64(1), int64(7), object(3)\n",
      "memory usage: 34.5+ KB\n",
      "None\n",
      "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
      "0   9.50        138      73           11         276    120       Bad   42   \n",
      "1  11.22        111      48           16         260     83      Good   65   \n",
      "2  10.06        113      35           10         269     80    Medium   59   \n",
      "3   7.40        117     100            4         466     97    Medium   55   \n",
      "4   4.15        141      64            3         340    128       Bad   38   \n",
      "\n",
      "   Education Urban   US  \n",
      "0         17   Yes  Yes  \n",
      "1         10   Yes  Yes  \n",
      "2         12   Yes  Yes  \n",
      "3         14   Yes  Yes  \n",
      "4         13   Yes   No  \n"
     ]
    }
   ],
   "source": [
    "carseats = pd.read_csv('./data/Carseats.csv')\n",
    "print(carseats.info())\n",
    "print(carseats.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Automatic Model Building\t\t\t\t\t\t\t\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gerardnico.com/data_mining/stepwise_regression\n",
    "\n",
    "In stepwise regression include regression models, where the choice of predictor variables is carried out by an automatic procedure\n",
    "\n",
    "Stepwise regression adds or removes predictor variables based on their p values.\n",
    "\n",
    "In forward stepwise selection model, we start the model with no predictor and add the best one based on p-value below the threshold value\n",
    "\n",
    "In backward stepwise selection model, we start the model with all the predictors and remove the variable with the largest p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4\n",
    "\n",
    "Apply stepwise regression to select the best features using the pre-defined, Boston data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  https://datascience.stackexchange.com/questions/24405/how-to-do-stepwise-regression-using-sklearn\n",
    "\n",
    "We will write a function to perform a forward-backward feature selection based on p-value from statsmodels.api.OLS \n",
    "Input parameters:\n",
    "\n",
    "+ 1) X - pandas.DataFrame with features\n",
    "+ 2) y - pandas series with the target variable\n",
    "+ 3) initial_list - list of features to start with (column names of X)\n",
    "+ 4) threshold_in - include a feature if its p-value < threshold_in\n",
    "+ 5) threshold_out - exclude a feature if its p-value > threshold_out # set threshold_in < threshold_out\n",
    "+ 6) verbose - whether to print the each step\n",
    "\n",
    "Output: List of selected features \n",
    "\n",
    "See https://en.wikipedia.org/wiki/Stepwise_regression for the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas           as     pd\n",
    "import numpy            as     np\n",
    "import statsmodels.api  as     sm\n",
    "from   sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list  = [], \n",
    "                       threshold_in  = 0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose       = True):\n",
    "\n",
    "    included_list = list(initial_list)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        changed = False\n",
    "        \n",
    "        # forward step\n",
    "        \n",
    "        excluded_list   =  list(set(X.columns)-set(included_list))\n",
    "        new_pval        =  pd.Series(index = excluded_list)\n",
    "        \n",
    "        for new_column in excluded_list:\n",
    "            \n",
    "            model                = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included_list+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "            \n",
    "        best_pval = new_pval.min()\n",
    "        \n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included_list.append(best_feature)\n",
    "            changed=True\n",
    "            \n",
    "            if verbose:\n",
    "                print('Add  %s with p-value %1.12f'%(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        \n",
    "        model      = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included_list]))).fit()\n",
    "        \n",
    "        # use all coefs except intercept\n",
    "        \n",
    "        p_values    =  model.pvalues.iloc[1:]\n",
    "        worst_pval  =  p_values.max() # null if pvalues is empty\n",
    "        \n",
    "        if worst_pval > threshold_out:\n",
    "            \n",
    "            changed=True\n",
    "            worst_feature = p_values.argmax()\n",
    "            included_list.remove(worst_feature)\n",
    "            \n",
    "            if verbose:\n",
    "                print(' %s with p-value %1.12f'%(worst_feature, worst_pval))\n",
    "                \n",
    "        if not changed:\n",
    "            break\n",
    "            \n",
    "    return included_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "X    = pd.DataFrame(data.data, columns=data.feature_names) # Predictor variables\n",
    "y    = data.target # Target or Response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  LSTAT with p-value 0.000000000000\n",
      "Add  RM with p-value 0.000000000000\n",
      "Add  PTRATIO with p-value 0.000000000000\n",
      "Add  DIS with p-value 0.000016684671\n",
      "Add  NOX with p-value 0.000000054881\n",
      "Add  CHAS with p-value 0.000265473059\n",
      "Add  B with p-value 0.000771945890\n",
      "Add  ZN with p-value 0.004651615937\n",
      "resulting features:\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN']\n"
     ]
    }
   ],
   "source": [
    "result = stepwise_selection(X, y)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Boston dataset contains the following features:\n",
    "\n",
    "**CRIM, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD,TAX,PTRATIO, B and LSTAT**\n",
    "\n",
    "Best subset of features selected are **LSTAT, RM, PTRATIO, DIS, NOX, CHAS,B and ZN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  In class lab :  Practice Exercise 4\n",
    "\n",
    "Use the data redwine and apply stepwise regression to select the best features to predict target variable quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take Home Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Use the Whitewine data and recommend a regression model which will be free of multicollinearity.\n",
    "Also take care of binary and multinomial predictors and interpret regression equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White wine data\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Input variables (based on physicochemical tests): \n",
    "\n",
    "+ 1 - fixed acidity \n",
    "+ 2 - volatile acidity \n",
    "+ 3 - citric acid \n",
    "+ 4 - residual sugar \n",
    "+ 5 - chlorides \n",
    "+ 6 - free sulfur dioxide \n",
    "+ 7 - total sulfur dioxide \n",
    "+ 8 - density \n",
    "+ 9 - pH \n",
    "+ 10 - sulphates \n",
    "+ 11 - alcohol \n",
    "\n",
    "**Output variable (based on sensory data): **\n",
    "\n",
    "+ 12 - quality (score between 0 and 10)\n",
    "\n",
    "##### Relevant Papers:\n",
    "+ P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. \n",
    "+ In Decision Support Systems, Elsevier, 47(4):547-553, 2009. \n",
    "\n",
    "\n",
    "#### Citation Request:\n",
    "\n",
    "Please include this citation if you plan to use this database: \n",
    "\n",
    "+ P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
    "+ Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           4898 non-null float64\n",
      "volatile acidity        4898 non-null float64\n",
      "citric acid             4898 non-null float64\n",
      "residual sugar          4898 non-null float64\n",
      "chlorides               4898 non-null float64\n",
      "free sulfur dioxide     4898 non-null float64\n",
      "total sulfur dioxide    4898 non-null float64\n",
      "density                 4898 non-null float64\n",
      "pH                      4898 non-null float64\n",
      "sulphates               4898 non-null float64\n",
      "alcohol                 4898 non-null float64\n",
      "quality                 4898 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n",
      "None\n",
      "                            0        1        2         3         4\n",
      "fixed acidity           7.000    6.300   8.1000    7.2000    7.2000\n",
      "volatile acidity        0.270    0.300   0.2800    0.2300    0.2300\n",
      "citric acid             0.360    0.340   0.4000    0.3200    0.3200\n",
      "residual sugar         20.700    1.600   6.9000    8.5000    8.5000\n",
      "chlorides               0.045    0.049   0.0500    0.0580    0.0580\n",
      "free sulfur dioxide    45.000   14.000  30.0000   47.0000   47.0000\n",
      "total sulfur dioxide  170.000  132.000  97.0000  186.0000  186.0000\n",
      "density                 1.001    0.994   0.9951    0.9956    0.9956\n",
      "pH                      3.000    3.300   3.2600    3.1900    3.1900\n",
      "sulphates               0.450    0.490   0.4400    0.4000    0.4000\n",
      "alcohol                 8.800    9.500  10.1000    9.9000    9.9000\n",
      "quality                 6.000    6.000   6.0000    6.0000    6.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "whitewine_data = pd.read_csv('./data/winequality-white.csv', sep = \";\")\n",
    "print(whitewine_data.info())\n",
    "print(whitewine_data.head().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Apply stepwise regression to select the best features using the concrete dataset to predict strength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1030 observations on 9 variables.\n",
    "\n",
    "**Attribute information**\n",
    "\n",
    "| Sl No | Variable | Description |\n",
    "| --- | ------------------------ | ---------------------------|\n",
    "| 1 | cement | Cement in Kg in a m3 mixture |\n",
    "| 2 | slag | Blast Furnace Slag|\n",
    "| 3 | ash | Fly Ash |\n",
    "| 4 | water| Water |\n",
    "| 5 | superplastic | Superplasticizer |\n",
    "| 6 | coarseagg | Coarse Aggregate |\n",
    "| 7 | fineagg | Fine Aggregate |\n",
    "| 8 | age | Age - Day ( 1 -365) |\n",
    "| 9 | strength | complete comprehensive strength, target variable |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 9 columns):\n",
      "cement          1030 non-null float64\n",
      "slag            1030 non-null float64\n",
      "ash             1030 non-null float64\n",
      "water           1030 non-null float64\n",
      "superplastic    1030 non-null float64\n",
      "coarseagg       1030 non-null float64\n",
      "fineagg         1030 non-null float64\n",
      "age             1030 non-null int64\n",
      "strength        1030 non-null float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 72.5 KB\n",
      "None\n",
      "Index(['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg',\n",
      "       'fineagg', 'age', 'strength'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cement_df =  pd.read_csv('./data/concrete.csv', header = 0)\n",
    "print(cement_df.info())\n",
    "print(cement_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
