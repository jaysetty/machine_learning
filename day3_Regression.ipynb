{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into Training & Test Data and use train data for Model building \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use advertising data to build a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                    as     pd\n",
    "import numpy                     as     np\n",
    "\n",
    "import seaborn                   as     sns\n",
    "import matplotlib.pyplot         as     plt\n",
    "\n",
    "import scipy.stats               as     stats\n",
    "import statsmodels.api           as     sm\n",
    "import statsmodels.stats.api     as     sms\n",
    "\n",
    "from   statsmodels.compat        import lzip\n",
    "from   sklearn.metrics           import mean_squared_error\n",
    "from   sklearn.preprocessing     import PolynomialFeatures\n",
    "from   sklearn.linear_model      import LinearRegression\n",
    "from   sklearn                   import linear_model\n",
    "from   statsmodels.stats         import diagnostic as diag\n",
    "from   sklearn.cross_validation  import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200 entries, 1 to 200\n",
      "Data columns (total 4 columns):\n",
      "TV           200 non-null float64\n",
      "Radio        200 non-null float64\n",
      "Newspaper    200 non-null float64\n",
      "Sales        200 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 7.8 KB\n",
      "None\n",
      "               1     2     3      4      5\n",
      "TV         230.1  44.5  17.2  151.5  180.8\n",
      "Radio       37.8  39.3  45.9   41.3   10.8\n",
      "Newspaper   69.2  45.1  69.3   58.5   58.4\n",
      "Sales       22.1  10.4   9.3   18.5   12.9\n",
      "(200, 3)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "Advertising_df = pd.read_csv('./data/Advertising.csv', names = ['TV','Radio','Newspaper','Sales'], header = 0)\n",
    "print(Advertising_df.info())\n",
    "print(Advertising_df.head().T)\n",
    "\n",
    "X          =   Advertising_df[['TV','Radio','Newspaper']]\n",
    "y          =   Advertising_df['Sales']\n",
    "\n",
    "print(X.shape)                            \n",
    "print(y.shape)                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Absence of multi-collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.2854621001628961, 3.0552445106573844]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "[variance_inflation_factor(X.values, j) for j in range(1,X.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We don't see any variable having VIF more than the threshold of 5. Hence there is no multi-collinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model to get residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   570.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 01 Dec 2018</td> <th>  Prob (F-statistic):</th> <td>1.58e-96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:21:07</td>     <th>  Log-Likelihood:    </th> <td> -386.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   780.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   196</td>      <th>  BIC:               </th> <td>   793.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>    2.9389</td> <td>    0.312</td> <td>    9.422</td> <td> 0.000</td> <td>    2.324</td> <td>    3.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>        <td>    0.0458</td> <td>    0.001</td> <td>   32.809</td> <td> 0.000</td> <td>    0.043</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>     <td>    0.1885</td> <td>    0.009</td> <td>   21.893</td> <td> 0.000</td> <td>    0.172</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Newspaper</th> <td>   -0.0010</td> <td>    0.006</td> <td>   -0.177</td> <td> 0.860</td> <td>   -0.013</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>60.414</td> <th>  Durbin-Watson:     </th> <td>   2.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 151.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.327</td> <th>  Prob(JB):          </th> <td>1.44e-33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.332</td> <th>  Cond. No.          </th> <td>    454.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.897\n",
       "Model:                            OLS   Adj. R-squared:                  0.896\n",
       "Method:                 Least Squares   F-statistic:                     570.3\n",
       "Date:                Sat, 01 Dec 2018   Prob (F-statistic):           1.58e-96\n",
       "Time:                        17:21:07   Log-Likelihood:                -386.18\n",
       "No. Observations:                 200   AIC:                             780.4\n",
       "Df Residuals:                     196   BIC:                             793.6\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.9389      0.312      9.422      0.000       2.324       3.554\n",
       "TV             0.0458      0.001     32.809      0.000       0.043       0.049\n",
       "Radio          0.1885      0.009     21.893      0.000       0.172       0.206\n",
       "Newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
       "==============================================================================\n",
       "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
       "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
       "Kurtosis:                       6.332   Cond. No.                         454.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build a model\n",
    "X_1       = sm.add_constant(X) \n",
    "model     = sm.OLS(y, X_1).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_1))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)  Errors between the observed and predicted values should be normally distributed\n",
    "\n",
    "* For regressions, the test of normality applies to model's residuals and not the variables themselves. \n",
    "\n",
    "* We shall inspect the residuals using a probabity plot. Here the residuals will be represented as dots (in blue) should fall on the red line.\n",
    "\n",
    "* We use Shapiro Wilk test  from scipy library to check the normality of residuals.\n",
    "\n",
    "* Null Hypothesis: The residuals are normally distributed.\n",
    "\n",
    "* Alternative Hypothesis: The residuals are not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P value is 0.0000\n"
     ]
    }
   ],
   "source": [
    "shaipro_stat, pval = stats.shapiro(model.resid)\n",
    "print('P value is %1.4f' %pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Since the p-value is 0, we decide that at 5% level of significance we reject the null hypotehsis and conclude that the residuals are not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try transforming variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 10)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "degrees = [2,3]\n",
    "\n",
    "for degree in degrees:\n",
    "    poly      = PolynomialFeatures(degree = degree)\n",
    "    X_        = poly.fit_transform(X)\n",
    "    print(X_.shape)\n",
    "\n",
    "    ## Build a model after log transformation\n",
    "    X_c         = sm.add_constant(X_) \n",
    "    model_c     = sm.OLS(y, X_c).fit()\n",
    "    shaipro_stat, pval = stats.shapiro(model_c.resid)\n",
    "    if  pval > 0.05:\n",
    "        print('\\nResiduals are normally distributed for %d degree of polynomial P value %1.4f' %(degree, pval))\n",
    "        print('\\nSince the p-value > 0.05, at 5% level of significance we accept the null hypotehsis')\n",
    "        print('and conclude that the residuals are normally distributed')\n",
    "        model_linear = model_c\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We shall inspect the residuals using a probabity plot. Here the residuals will be represented as dots (in blue) should fall on the red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x251908a7e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats.probplot(model_c.resid, plot= plt)\n",
    "plt.title(\"Model1 Residuals Probability Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "This plot indicates that the modelâ€™s residuals are normally distributed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Homoscedasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking heteroscedasticity Using Goldfeld Quandt we test for heteroscedasticity.\n",
    "\n",
    "* Null Hypothesis: Error terms are homoscedastic\n",
    "* Alternative Hypothesis: Error terms are heteroscedastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('F statistic', 1.6923694864230754), ('p-value', 0.0098423621433530173)]\n"
     ]
    }
   ],
   "source": [
    "residuals = model_c.resid\n",
    "name = ['F statistic', 'p-value']\n",
    "\n",
    "test = sms.het_goldfeldquandt(residuals, model_c.model.exog)\n",
    "\n",
    "print(lzip(name, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Since p-value is 0.94 and > 5%, we accept the null hypothesis and conclude that Error terms are homoscedastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Checking for autocorrelation \n",
    "\n",
    "To ensure the absence of autocorrelation we use Ljungbox test.\n",
    "\n",
    "* Null Hypothesis: Autocorrelation is absent.\n",
    "* Alternative Hypothesis: Autocorrelation is present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('test statistic', 1.6923694864230754), ('p-value', 0.0098423621433530173)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = ['test statistic', 'p-value']\n",
    "diag.acorr_ljungbox(residuals, lags = 1) \n",
    "\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Since p-value is 0.94 and > 5%, we accept the null hypothesis and can say that autocorrelation is not present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Relationship between the independent and dependent variables to be linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual vs fitted values plot is used to check for constant variance and linearity, and to identify potential outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAElCAYAAADk/ZWYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xt8XHWd+P/X+5y55X5p06S0tKm0\nRQpaYItAV7FWdiX+XF1xva67rOtuVvlVd9klC6yLN74IfqsiWr/ydV2l3nBxBRWkisgiSAEtCpYW\naIG0aUouTZv7bS7n8/3jnJlO0plkksxkJpP3s48+kpk5M+dzzsl83udzF2MMSimllJXvBCillCoM\nGhCUUkoBGhCUUkp5NCAopZQCNCAopZTyaEBQSikFaEBQGRKRfSKyJc1rW0SkPUv7eUhE/i4bnzXL\n/b9ORJ7P8T5ycowickhELs3256rFQwNCkfEyhVERGRKRThG5XUTK5/q5xpizjTEPZSGJsyIi7/WO\nTSY97xORbhF5yww/z4jIsHeehkSkD8AY84gx5syk7SZksiLS6L3XN9djWui8GwHHO3+DIvK8iHzA\ne23K8yQiG0TkJyLS7733f0Rks/fa65Kuy7D3OUNJ/1fN53EuJhoQitOfGWPKgXOB84Dr8pyebLgb\nqAZeP+n5ywAD/GwWn7nRGFPu/a+eawIXqZe9v7VK4BrgP0Rkw1RvEJEzgEeBvcAa4DTc63u/iFzs\nBeVy73PP9t5WnXSt2nJ2NIucBoQiZozpBH6OGxgAEJGgiHxORNpEpEtEbhOREu+1pSJyr4j0icgJ\nEXlERCzvtcSdsoiUeCWPXhHZD1yQvF/vjm5t0uPbReR/eb/XePs45r3/XhFZmcGxjAF3An896aW/\nBr5rjIlOlf5MJVd/ici3gVXAPd6d6b8CD3ub9nnPXext+7ci8qx3TD8XkdVJn/knIvKcdze8AxBS\nEJHTvNJdbdJz54lIj4j4ReQMEXlQRI57z31XRFIGsuRzPvm4kvb1Q+86tIrIR5Nee42I7BGRAe9v\n5AvTnTfj+hHQC0wZEIBPAo8ZYz5mjDlhjBk0xnwJ+Dbw2en2pXJHA0IR8zLaJuCFpKc/C6zHDRJr\ngRXAx73X/gVoB+qAeuDfcO++J/sEcIb3/03AFTNIlgV8E1iNm9mOAjsyfO9O4C+SAlgV8GfAt2aY\n/owYY/4KaMMrcRlj/jdwifdy/I71MRH5c29fl3v7fgS4w0vjUuCHwL8DS4EXgT9Os7+XgceAdyQ9\n/T7gv40xEdxAchPuHfVZwOm4meuMeEHyHuBp3Ov/RuCfRORN3ia3ArcaYypxr/GdmXymiLwdtxS3\nd5rN/wT4QYrn7wT+WERKMzoQlXUaEIrTj0RkEDgCdONm4IiIAH8PXBW/MwM+A7zHe18EWA6sNsZE\nvKJ7qgz1XcCN3mccAb6UacKMMceNMT80xox4+7+RU6uB0r33UaALeHtSOg4YY56aYfrjfueVJvpE\nJONjSOEfgJuMMc8aY6K45/Rcr5TwZmC/MSaeqX8R6Jzis74HvBcS1+s93nMYY14wxvzCGDNujDkG\nfIEMz90kFwB1xphPG2PCxpiXgP9g4t/BWhFZaowZMsY8PsVnnSZu+0sP7t/ZXxljpmuUXwp0pHi+\nAzdPqpnJwajs0YBQnP7cGFMBbAFeifsFBPfutRR4Mp4R4ta913mvb8ctTdwvIi+JyLVpPv803GAT\ndzjThIlIqYj8XxE5LCIDuFUw1SJiZ/gR3+JktdFf4ZYa4jJNf9z5xphq7/9Hp9l2KquBW5PO6Qnc\nu/kVTDpXXoA6kvJTXP8NXCwip+GWRgxuiQMRWSYi3xeRo965+w4nr+1M03taUjDswy3h1HuvfxC3\nFPmciPxWpm6wf9k7f7XGmHONMd/PYP89uIF7suWAg1vtpPJAA0IRM8b8Crgd+Jz3VA9uFc3ZSRlh\nldd4h1eX+y/GmFfgVsX8s4i8McVHd+BWV8RN7vUxght44hqSfv8X4EzgQq9KIl4Fk7JePYVvAW/0\n6u4vwrt7nmH6Z2JyCSNVieMI8A9J57TaGFNijNnNpHPl3fWfnuIz4sfQB9yPW/p5H3BHUinnJm//\nr/bO3ftJf96GSX8NjgCtk9JbYYx5s5eGg8aY9wLLcKsY/1tEytKleRYeAN6Z4vl34bYtjGRxX2oG\nNCAUvy8CfyIi5xpjHNyqgVtEZBmAiKyI1x2LyFtEZK2XaQ0AMe//ZHcC13kNxCuBj0x6/SngfSJi\ni8hlTKzWqMANSn1e4+knZnIwxpjDwK9x6+h/4TWcM8P0z0QX8Iqkx8dw72KTn7sN93yc7aWjSkTi\nGd5PgbNF5HJxu2B+lImZcyrfwy0FvYOkgId77oZwz90KoGWKz3gKeLOI1IpIA/BPSa/9BhgQkWvE\n7SBgi8g5InKBl/73i0id9/fS571ntucxKCKhpP8W8Clgs4jc6KWvQkQ+4h3zNbPcj8oCDQhFzqtr\n/hZwvffUNbjVKo971Q4P4N6xA6zzHg/hNm7+nzRjDz6FW03Uins3++1Jr/8j7h16H/CXwI+SXvsi\nUIJbWnmc2XUX3Ylb7fGtSc9nmv6ZuAn4d69q5Wrv7vVG4FHvuYuMMXfj3kl/3zunz+A25mOM6cG9\nG74ZOO6l8dFp9vkTb7suY8zTSc9/Cjgf6McNNHdN8Rnfxm00PoR7jf4r/oIxJoZ7fc7FvYY9wNeB\nKm+Ty4B9IjKE28D8Hq+X12wM4d4AxP9vNcYcBF4LbPTS14Eb/N7ktROpPBFdIEcppRRoCUEppZRH\nA4JSSilAA4JSSimPBgSllFKABgSllFIeDQhKKaUADQhKKaU8GhCUUkoBGhCUUkp5NCAopZQCNCAo\npZTyaEBQSikFaEBQSinl0YCglFIK0ICglFLKowFBKaUUoAFBKaWURwOCUkopQAOCUkopjy/fCZiJ\npUuXmsbGxnwnQymlFpQnn3yyxxhTN912CyogNDY2smfPnnwnQymlFhQROZzJdlplpJRSCtCAoJRS\nyqMBQSmlFKABQSmllEcDglJKKUADglJKKY8GBJUzuw7uYuvOray5dQ1bd25l18Fd+U6SUmoKGhBU\nTuw6uIttu7bRMdhBbaiWjsEOtu3apkFBqQKmAUHlxPbd2wlYAcoCZYgIZYEyAlaA7bu35ztpSqk0\nNCConGjta6XUXzrhuVJ/KYf6DuUnQUqpaWlAUDmxpnoNI5GRCc+NREZorG7MT4KUUtPSgKByomVz\nC2EnzHB4GGMMw+Fhwk6Yls0t+U6aUioNDQgqJ5rWNbGjaQfLK5bTO9bL8orl7GjaQdO6pnwnTSmV\nhgYElXMGk+8kKKUyoAFB5YR2O1Vq4dGAoHJCu50qtfBoQFA5od1OlVp4NCConNBup0otPBoQVE5o\nt1OlFh4NCConstXtVCfIU2r+iDELp0vgpk2bzJ49e/KdDDVP4j2VAlaAUn8pI5ERwk5YxzMoNUMi\n8qQxZtN022kJQRUs7amk1PzSgKAKlvZUUmp+aUBQBUt7Kik1v/IaEETkGyLSLSLP5DMdqjBpTyWl\n5le+Swi3A5flOQ2qQOkEeUrNL18+d26MeVhEGvOZBlXYmtY1aQBQap7ku4QwLRFpFpE9IrLn2LFj\n+U6OUkoVrYIPCMaYrxljNhljNtXV1eU7OUopVbQKPiAopZSaHxoQlFJKAfnvdnoH8Bhwpoi0i8gH\n85mexahQ5woq1HQpVcx0LqNFrFDnCirUdCm1UOlcRmpahTpXUKGmSxUOLUHmhgaERaxQ5woq1HSp\nwqDrdeeOBoRFLBdzBWXjzk3nMFJT0RJk7mhAWMSyPVdQtu7cdA4jNZWpSpBalTQ3GhAWsWzPFZR8\n5zYwPsDRwaMc6T/C++5634y+mDqHkZpKuhJkRaBCq5LmSHsZqaxZc+saakO1DIwP0DbQhiBYWERM\nhFVVqzRTV1mRrhdaeaCccDRMWaAsse1weJjlFct58IoH85ji/NNeRiqt6YrVmRS7U20Tv3PrGu5C\nEGzLxmAo8ZWcUserRXs1W+lKkAPjA7PqjKB/iydpCWGRma6PfyZjANJtc8XGK9j59E6O9B/BJz4M\nBgeHVVWrqAxU0jvWy0v/+FJOxhnsOriL7bu309rXyprqNbRsbtHSyCKzdedWOgY7ZlRCWCxjXrSE\noFKarodGJj040m3z0KGH2NG0g7JAGRETwW/7WVW1iqpg1YReQtnuJaLdEBXMrjOC9liaSAPCIjNd\nH/9MxgBMtU3Tuia+d/n3WFW1ihUVK6gMVJ7yxWztayXiRDhw/AB7u/dy4PgBIk5kwj5mUozXL7WC\n2XVG0DEvE+V1gRw1/9ZUrzmlWJ189z7V6/Fqmc6hTrqHujmt8jSqglWnfEbTuiZ2sIPtu7dzqO8Q\njdWNE6pwKoOV7D+2H5/48ImPSCzC4f7DbKjbAEwsxiff8e9gB8ApVUOtfa3UhmonHOdcv9RaBbUw\nzXRBpem+D4uNlhAWmemK1ele39K4JVEts6J8ReKOvm+sb8I28bv67bu307K5hZf+8SUevOLBiV9S\nA4Jgkv4JAl5zVro7/mt/eW3KqqHKQGVWB7JpFdTMLdSGWR3zMpEGhCI3+YsKTFmsTlfsfujQQ4lM\nurqkmtVVqwlYAY4OHGV5xfJEg3ImmehAeIBVlasI2AFiJkbADrCqchWD4UEgfTH+QM+BlIECYdov\ntVZB5c5CDqA65mUi7WVUxLLZgyI+xkBEEs8ZYxI9h2bSw2O6bdO9fqj/EBuWbkiZhq+8+Stpq6hm\neh6mO1Y10Wx696j5pb2MVFbvdKebX2gmjXOzrbZaX7s+bRqa1jXx4BUPpqyimul50LmUZkYbZouH\nBoQilskXNdOqlOky8ZlkotMV09O9fvOlN6dt35jqGGaaYWm98sxoAC0eWmVUxKYrys+0KiXe8yYb\n1TKzNTkNWxq3sPPpnVPud7YDltIdaz4VYu+nVNe+d6yX+vJ6BsYHCiadi1mmVUYaEIrYdJl0tut+\n85GJZnIMhT4aNdNMvpCPI/naVwQq6B7upjpUXXDpXKw0IChg6kx6oTWepso4r7zvyrTHEG9obu1r\npTJYCQYGw4MFd8efaSa/UBpvF0o6FxMNCGpaC+mLmy7jdByH7uFuoiZK0A5SX1aPz/IRsAMMRYYK\n8m462UyuwUIJ4AslnYuJ9jJaxLLVUFwI4sdy+X9dTudgJ1EnmugpFI6EeXnwZcJOGDFCOBbmcP9h\nesd6QZiyZ1Gqc5T83MbbNrLxqxtzPtBqJg3eC6XxdqGkU51KA0KRyWSQUDzju/K+Kyn3lxPwBXI2\nKGcuI1iTjyVmYsRMjLaBNvrH+gHoC/cRdaL4LT9hJ0w4FkaQRGPmVKtqTT5Hf/vjv+UDP/4AHYMd\n2GLzTNcz7O3eS3t/O0+0P8EHfvyBOQeFqaYMT5Yu88w0gOd71PB83Wjk+ziLkVYZFZmpqiBaNrdw\n7QPXsr9nPwErwPKK5YnMNBdVKXNtBE0+lgPHDxCJRTAYAnaA9UvW8/uO3yceW2LhGAeDoSZYw4Zl\nG9Keh+Ojx3nh+Asnq5nK63l54GUAzqo7i33d+xiLjQHuFBsBO4BjHM5aehZPf/jprJ6L+AjvbPT0\nysY5z5ZcdzAolONcKLTKaJFKVwWx/9h+tu3axgsnXsAWG8c4HBk4QtREczYtQ3xAWNREOXjiIC/1\nvUTnYCfX/vLaGR9LfXk9Dg4YGI+OMxweBgFLLGzLRsRdkAcD4874lHMy7T+2n5gTwyc+xqJjvHji\nRUaiI4xGR+kf72c8No54/wBsy8YSiwMnDsz5XCRXYYUjYW55/BaGw8N0DncmpgHJJFMzpL6Ry+W0\nGzO5I29a10TL5hYaqxtp7Wtl++7tWb2DTzvf1QPX5rzUUMwlEw0IRSZdFcR4bDyROVtiYVkWFhZd\nQ105G1Uan+b6UN8hhsPDRGIRRqOjPNP9TEZfouRjqQpWsapqlZs5WxbLK5ZTGax0SwaOGygcxy0h\nBO1gysFtV2y8glsev4WYEyPshIk4EaJOdMI+2/rbgJMZbqJh1ECaPDjjc5EcqPvH+uke7WYoPMSK\nihU0lDVQFixjS+MWtu/enjKzmao6MJ5JPXz4YdoH2xPVapCdUcMzna8oG/MbTZXxprrxicQi7O/Z\nn9M5lRbyvE2Z0IBQZNLdGceL1kE7iGMcwL27Ho+N56zBb031GtoH2ok60cSMpgaDMSajUsLkY/GJ\nj4aKBu561108eMWDnNdwHlXBKiJOhJHoCBEnQlWwKjGNdvJ0Fi2bW9j59E6Gw8OJ1dwiTiQx2yq4\nQSDmxBIlg/g5GouMMe6MY1v2rL/4kwN113AXGCjxlZwsMcTC3PTrm9JmNlPdFcczqRJfCeFoeEJb\nSzau70xLHnMtqUyX8aa68ekY6sj5pITFPvGhBoQik27ah7OXnc1IZIT6svpExhevNplpw+RMejGN\nx8YTj+NBwcbmQM/01S/TTXGxpXELfeN92GJTYpdgi03feB9bGrec8lnxL3LIF8KyLHeW1En84scx\nDg4OATuAbdmJYOazfNQEa2Z9Nzg5uI1FxzAY6svrE9v0jfYRc2JpM5u0s8CeODkLbENFAwhgoHO4\nc84zv8a19rUSiU1a1CgWSVvymOv8RtNlvOlufJZXLE+7z2xU9RT7vE0aEIpQqone4l8gn+Xj9IrT\nscUmRoy1S9aeUmc9XdXEbIrM8btwv+XHtm2SbsJndCxA4kt9y+O3UBWsIugLEiNG0BekobSBhw49\nNOFYkqtSfOIjHAsTdsKJbQQhYAXw+/z4LT/VoWp+9O4fUR4ox2/5KQ+U01jVSH1FfSJTmmnmMjm4\nlQXKqC+vTywwBDAWGyPoC054X3Jmk646EEMik4pXrQXsAGORsVOC6GyvX2WgkraBNsKxMLbYhGNu\nKaQiUJFy+7l2PZ0u4011s7ChbgN+y59yn9mq6snkuBZyG4P2MlpEMu35MVVPJYCOwQ6iJkrXUBfj\nsXF84mPtkrU8/aGnJ+xr265ttPe3T8h841/Y2fTYmdyzZG/3XgBWV69OZKzJA6CSt28faGc0MkqM\nWKJRPR6kLCyCvuCEXkqdLZ1pB1gdHThKWbAsbQ+XTKaiSNVL5lD/IZaGllJfcbLUkMncU+WBcsLR\ncNqeZclpOT5ynHAs9baTB8IlH8ex4WOMRcfwW/5Ej66oibKhbsOE6z7V8c22h9l06cxkn9t3b8/K\nIMzpjqtQez9pLyN1iqmmiE421d1ZvKG4rb+NSCyCT3zEnBj7j+2fcCcUL/Kvql6FLTaW96cWMzFq\nS2q5+dKbZ5z+5GqEgfAAjnGIOBFae1vpHz+1vvzaB66lc7CTl/pecscxEANINDwLgoWFiCQW6llW\nsowNy9w2iLQN9M542uqMyXeiB3sOcvmdl9PwuYYJd4up7nCve+11BPyBtP33084C+8b0s8BOvive\n37OfSCySOJ7+sX7aB9t55PAjE9I3+TjCMTeoiwhRE8Vv+1ldtZrB8cGU12quC8/MZizDVPvMVlXP\ndMe10NsYdE3lPJrJpGbzOcPldOvMPtH+BBZuTyXAHRUs7h99PF3xdY4HwgNu9UXU7ddvi8033/bN\nWaU//pn94/209bdhYRHDHbB2uO8w9eX1BOwALZtb2HVwF/t79mOLnSgRxMUDSU1JTSJDO6funMTd\nXPK6DNt2bYMwE+72gnYwbeaSnCHEexJh3LvR5LWhm9Y18duXf8vvO3/P4PggvWO9bGnckribTVeK\nS7dmcKo1rJPTAiQyp46hDqpLqukf66dtoA0MhHyhCemb/N6QL8R4dByf5WPDEjdgJpcap5Kui+xU\npluXe6r3pVz0KItrJ0+1bnMu1veeT1pllCf3Pn8vH/nZR/CJj5AvlOgaevXFV3Pe8vMYjY4yFh3j\nsSOP8c2nvoktNgE7wHhsnKgT5R1nvYMzl57pNg4bt4E46kQTv8d/xqtBHONgjEn5eMJzGI70H+GJ\no26mH29YdYzDecvPwxjD7iO73Z44XuOlwVDiK8FguGT1JTjGYc/Le9wMNH5n6fUwAnjl0ldSGayc\nkA4RIepEae1tZSg8hCA0VDRw5aYrWVq6lO/84Tv85uXfYGEleipZlkU4GsZgsMSiLFDG9y7/XmIm\n1yfan8AxDpZlEXNiiQZuS9xGZQeHykAlUROlJlSTdqBXqow2XfVDPEMQEQ4cP5Coc4+aKK9a9qrE\ndlsat3DDwze451hsYiaGg8P1l1zPx1//8az8jaWq8uob6+Nw/2HW1qylfbCdcDQMAquqVlEVrEp5\nHP3j/bT3tycG651Rc8a0AxozqVqZz5uc+arKKdT5wXRyu1mK9wAZDA8yOD6Y8udQeIix6BijkdFE\nxj3h9+goo5GTv6faNuJEpk+MSite1QPQUN5ATaiGofAQrf/UCriZoS02RwaOYGG5E+F5pQS/5cdn\nuVVdlmVx17vumlEmNVXmcu0D1/L88ecJx8ITGtJDvhDrl6xPtHH0jvUyEnaro6ImSvx7WOIvYfjf\nhrNyjtJlTgFfgCUlS3jk8COEfCEaKhpOaYNprG5MtBXFS2NRJ4qDgyUWG+o2cPMbb0573qYKmvGS\n13zXs8/H9OwzCTzzGRQXREAQkcuAWwEb+LoxZsqK5dkGhP/83X/SOdQ5MXOflNEPhYcSv8dMbHYH\nlEUB2+0iORQewhZ3JG68f7yIEHNinL3sbLdKxLLxWb7E78k/LbGwxM08LbHcevOkx6meSzxGUr5/\nT8cennz5SRzj4LN8BH1BbLG59BWXsrZ2beJ9X3z8i0ScCDETw2f5KPeXE/QFGYuO0bK5ZcLnfn73\n5+kc7kwcf3KJYiaWlCwhHAszHBnGwqLUX0o4Fk7c3frFT8gfcgfq2QHKfGV0tnTO+It87QPXuiOX\nDaxfup53nPUOfvjsD3mm6xl3RHWK6wm4DfC1a9l3bJ+byZqTA+Pix3vf++7LSsYwl/Uw4pl252An\nMScG4qZvVeUqfJZv2obuofEhVlauTDnjaTzYFNJddDYz50wCz3w3PmcaEPLWhiAiNvAV4E+AduC3\nIvITY8z+bO/rM7/+DC/1zm3a3ZAvRHmgnIpABeWBckr9pZT4Swj5QpT4Tv485Tl/Scrfr/vldZwY\nOZFofIoPgIp/KWzLBmZeBI3/Mb54/MWc3HXsOriLn734M5aXLacv3Md41K3CanltyylVHY+1P3ZK\n2rsGuzAYvva7r7Gmeg1bGrfww2d/eEowAHe20ngPpaAdTFQVxRy3esVv+U8paR0fPZ743cFhIDww\n4fWIiWCiBr/lxxhD2AnT+MVGjg4excKirqwO27IJ+UKYiJnQLhI//vgXecPSDYxERuga6uKrv/0q\nA+MDaYNYJBZxj8eE6R7uJugLMhoZdY83aTS0IKfsc7amq4dP10YS32YHO7j8zssTjfD1ZfVUhaow\nxiTqxFO1UxCGsBNmJDKSss4+2/Xsc83Mk69pcpfUeFvPbE11Q5PuvGXr2s9WPnsZvQZ4wRjzkjEm\nDHwfeNtUbzh8+DD33HMPANFolObmZu677z4AxsbGaG5u5v777wdgaGiI5uZmHnzwQc5ffj4XLL+A\nFWMreH3d6/mbc/+GD77qg5w7eC7/sPYf+HLTl7l1y61cevxSbt10K4998DEeuPwB3tv5Xh780wcJ\n/3uYZ//yWd5+8O3cveVu/vDhP/CdLd9h3aPr+Ny5n+Oud9/FJ875BPZPbT5yxkf43J9+jvfUv4fD\n3znMW+veyocv+DDnW+fz4JceZGNoI29a+yb+ruHvqHqgCjPgftliR2KU/LyED5/1YWzLZvfu3TQ3\nN/OhDR8i7IQZe3EMc49heMDtbfFm35tpbm5maGgIgPvvv5+/+Ku/YNs9Xs+QI7X03tnLtp+6fa3v\nuecempubE+fy7rvv5sorr0w8/sEPfsBHP/rRxOM77riDq666KvH429/+Ni0tJxsq61+s58zfn8mr\n619NY1UjP7/z51x//fWJ7W+77TbO+MMZJ3uKPGEY+eUInSOdlAfKqX2qls6fdXLDwzfw3LHnOP2Z\n01n5zErA/SKt3LuSur11gJtJrnhqBcv3L8dvu2MFGp9qpOG5BnyWjzJfGWc8fwZ1R+so85dhi03l\nsUpCw6GUf0dRJ8podJThyDC9Y70c7j9M1IkSdsIcHTzKvmP7eKrrKQ4cP8AjbY9w0dcvovHaRi77\nymVc+dMrGR4bJvxEmKGXhrDEYnB4kKpfVlF2xP1y+yI+1u9eT3VHNQD2uM263euo6XbbKWqcGtY+\nupaK7gp30NuIj7WPrqX8WDn1ZfW0HWmjubmZJ598EoBDhw7R3NzM00+73TtfeOEFmpub2bdvHwDP\nP/88zc3NPP/88wD8x8/+gwvfdiFrP7mW7bu38+6l7+bSfZfyjdd/g6Z1TTz55JM0NzfzqpJXsaNp\nB8GuICN3jdDe0U65v5yDTx2kubmZC2ou4OKVF7NuaB3rd6+nCrdaafyFceoerGNoaMjtvdNWCvcA\nXmGn9FApKx9aSTjqXfvnDbEfxxLBZkX7Cpx7k0pR+yB2XyzRwJvuby/u9ttv57rrrgPczPzqz17N\niZ+eSGTmV990NX//L3+f2H7Hjh3ceOONicdf/OIX+exnP5t4fMPNN1D+2/KTPYN+U0b5k+WJnkE3\n3ngjO3bsSGz/qU99ittuuy3x+Prrr+frX/96Ij3XXHcNPY/2JNJzzTXX8LFbPpbY/qqrrqLjsY6T\nHRN2uecgHhSvvPJK7r777sT2zc3Ns8r3APr6+iZ876eTz15GK4AjSY/bgQsnbyQizUAzQFVV1eSX\nM/KDd/6Avr4+/vVf/5X3N72fSy65hJ6eHv7tZ//GX6/5aza/ZjOdnZ08M/YMFy69kAtXXkg77ZTH\nyqkMVOK3/dPvZIYuXHkhD9Y+SE9ZD21jbawsWcmy2mWnjLLdumYrO6p38JnvfoYBZ4D68nqueeM1\nBI8EOcDE0b5HBo6cvOsQd1K2eJe3q2qvIhvS3d31jvWesu3KypWJevWe0R4kItji3n2LuOsXWFhE\nnAiWWFNW1cWrNh3HSYwlqAhVsKx+mbuBA6Mjo4m+8svalzFeNU7P+h6iTpRz953Lpgs28Xj547QP\ntBN6KcRo5Sjj1eMYDOH+MJE0iEwJAAAgAElEQVRABGOfvKszYog6UZ44+gSUwOGewycTtNb72eP+\neP6i5xHHreaK2lHaN7QTDrmlG8fn0PWKLqwqC8K42y03BKoCCELUjtJf30+gIoDBYAdtni99np8c\n+Ql77b0c7znOgZID3Nt2L3tlL11dXbxQ8gL3td3HXrOXjo4OXix5kZ+1/YxvtX+Lb+z+BqGKEJbf\n4sDxA3zqhU+x2lrNva33Uj1QzcEjB3m29Flu3387h8cOc9QcxbfKR3lZOe0D7Xzy6CepLaul5aEW\n/JafI/4jWGssGILoUBQn5FD2yjIu+6/L6B3tpTvYjZwp0AsIOCUO1qssVtgrODp4lEhJBHuDzSp7\nFTc+ciPtNe30rO/BHHM7Bphyg6wV7DGbpu820dnRSX9ZPy/e8SIiwtHOowyEBmi9sxVLLA4fO8yg\nf5C2u9r45Uu/ZLx2HLvCBm/6JmeJw09iP8G+10YQ9g3tIxKL0LWrC0ssnhp9ilgsRs/9PW7jf/kB\nfJYPGXA7SkiNYCxDW2cbN/zqBh52HqZktIShX7s3AI/yKJXDlYw+NoqI8Bv5DS8Ovcj4b8b50hNf\nYqR2hFhpjBPHThB1oiypWsJ3jnyHM58+E0ssnvM/R8wfo3Ook6AviFQJ+GF8aJya0hpag63sGdhD\n8KDbNfpI8Ai/H/g9Zx4/k1dUvSLzL+ss5K0NQUTeCbzJGPN33uO/Al5jjPlIuvcUUy+jqXz6V5/m\nlsdvYXB8kIpgBVdddFWiOmaq4vGaW9dgY9M90s14bJygHWRZ6TIcnKytVDVdFdbk9G1p3JKY3vml\n3pfctgExrKpaRVt/Gza2O0LXDjIeGz+lmO2z3HuWgBUg4kTwW34qg5WMxcaIxqKJbqD15fV0DnYy\nFBmi1FeaGAkdc2L4bT91pXWnnIPkXjjJXTAd47CicgVj0THeffa7WVa2jM6hTrqGu7j/xfsZjYwS\nNdEJXVmVyrV/vuif+fybPj+r9xZ8GwJuieD0pMcrgZfzlJaC8elffTrRHTFgBRgJj3DDwzcAcMFp\nF0xZ11kZqOTZnmfdKaGTphc4a+lZWUvfVPXOqepib/r1TSwNLaWmooagL5goFXQNdRG0g4xERhCR\nRKNvsoDl3kFHTIS1S9YyOO6uh7ylcQs3/fomHMdt1I7E3IFylYFKRqIjRJ0otnVyNHJ1oDplf/Pk\nvulVoSpWsYqXB1/GMQ6vqHnFtI2B8Ub/3rFejHG73oadMMdGjiW2j3eTFRF3G38JMSfGmuo1lAfL\nOTF6gq6hLndxH6+zQLyx3Rh34r2aUI3bpuG1ocR/xo8v+bnesd4Jk/MlB9glJUtwjEP/eL87p5Rl\nMxYdQxCCvqB7l4wkugD/0fI/4sDxAwxHhqkMVHL+8vNZW7uWgB3Ab7s9tSyxOHj8II8eeZTesV5q\nQjVcsvoSzlxyZqIjxOT0Jro6p3nuxd4X+c3R39A/3p/Y76qqVSm3/enBnzISGcFn+RLHGo1FCflD\nvKHxDWn3mfz8seFj7D+2351CXexEG9UZNWdQHaqe9v3Jzx3uP5xoGzrl79kOsLR0aWLb8Zg7jXvM\nuNc8aAcTf7epzk+8XTGX8hkQfgusE5E1wFHgPcD78piegnDL47dgYeGz3Uvjw0c0FuWWx2/hvIbz\npm6IkpMTyMX/GbelMmumaqjcunPrKemLOlH6wn3UU+/Wjw+400uPRceoClYxGB7Exp7QgAxuMPDZ\nbtfQkBViScmSxBQJW3duZWloKd2j3cRMLNE43DPagyCETRjb2JT4S6gOVBPwB1KOcJ0c3HyWO5vq\nVD09Uh3/l5q+BJB4LuJEKPeVJ6ag6B/rTwSaC1dcmNGUIf1j/XQNdzEWHSPiRNj5lp1ZmfJh8usH\njh9gPDqO3/JTX15P11AXI5ERgnaQg8cPUhOqYUXFCkYiI+zv2c+VF1x5SiP7Q4cewmA4r+G8OffO\nufaX17L/mLeAU7nbZvTMsWf40KYPzWq8w0z2nY0uqbsO7uKt338rNvbJzB2H0ytPxzHZK6nnSr67\nnb4Z+CJut9NvGGNunGr7xVBl5Pu0z70ztpLu8hx3quaVVSunXLw83ve+ezipyqhs2bz9IaYaCPV8\nz/OJ3ibjsfHEHZglFiF/KFGSiQ8aiw9ks8RKjIY+veL0CdVe8f0MjA9wdPAoo9GTd2RBO0jUcdd8\nqC2pZUPdhim/3Lnomz7bTCr5uNoG2hJTa0RMhFVVq1JOQrh993b2H9ufWO+ioaKBrqEuakI1Kfc9\n+RrFq8oSJZOkAYcODo3VjYkxCpN7t2Wz62T8s6br5pruvbkeXzATG2/beMqKfD6Z+hhybSFUGWGM\nuQ+4L59pKDQVwQpGwiP4ki5NzMQoD5ZPO/w+/vr6JesTr2c6vUA2pEpf0BdkKDLEeHR8QnH8Y6/7\nGN986psTRsPGF6cBEkXlulAdfts/4Rji+6kKVdE13DVhfEa8WG2LzYa6DdN+AaeahmC2ZjvtQvy4\n4sdkWzaO41DiK0l0Dpg8a2k4FubE6AkEYURGEtVsATuQ6PM/oZ1p0jWqClWxLLKMzhG322/QF0yU\n5Gxj0zXUlQgIk7uGzrbrZLqBbPEFnHyWD8Rt/+ka7mJd7bopu6Tm4hrOxc1vvDlloMz2mtK5oJPb\nFZirLroKB4doLIpxDNGYOzr0qouumnbCr1wubp7JlL6p9j8cGWZpydKJU1SXu1NUJ08e1zXUhYWF\n3/IjCCE7RMAO0D/ef8oxJO9nPHqyITo+k6ol7qjafM4fk24iwanOY/y44lN+xKczqQhUpM2M+8f6\nscXGZ7v1/z2jPQyMD3Dg+IGUgSjVNQr43TafVy17FeuXrKcqVEXQDoIwYT2L5KmkE1OKD7QnJhaE\n6ccTpJuGel/3vikXcKoIVORtSum5TnU+04n98kkDQoH5+Os/zvWXXE9poJSIE6E0UJqY32a6P7Rc\n/SFmOpd8qv3H5+dfv2R9IsNZVrqMQ32HJmRO8QVjRISG8gb8tj/RuDb5GOL7CfgCpyyBCSRGUOdi\nFbi5mO48Nq1r4uKVF7vtIl6Qi2fy3SPdE44nPnvneGwcS9yvsWMcxmJj7jxWJpbyOk23gFJcfVm9\nex7Fl3YG1RJ/idtxob8t5WyzqaSbDTQeCONrZzuOk9h/71gv3cPd875s5a6Du9h420be+v238kT7\nE9jYGe8705mFC43OZbQIzHUk51wm7JpuPp193fsSQcFv+Tmt4jSqQqnrrCcf07Zd2whHwnSOdCYC\ng99yA4klFjWhGs5ednba3kLzObkaZNZl9/I7LycSi0wYk2Fj4/f5E3MuJX/W0cGjRGIRLMtiNDLq\nTvTn9WwqD5RTFahi3dJ1016nVO0BvWO91JfXJ3p3TZ6jqH+sn9a+1sQdfYmvhIpgxZSz2aZdY2Lw\naCI4RJwIHYMdhJ0wG5ZuACHj9R6ydR3n0qZRiHQ9BAVkZ1Hwucwln6qKom+sj66hLjoGO1hZuZKG\nsgZqS2qpDFa63QczqO5KjJiuqKeupC5xlxxxIhhjqC+tZ2XlypTHm6+F0qc7j9t3byfquA2RQTuY\nOCYEqgJVKat+qkJVxEzMrWL0ShXxaT3CsTDdo93s755+NphUJYdvvu2bPP2hp/nKm78CwJX3Xclj\n7Y9NWE8hnrEnl2imkm6NiQ11GxL7d4zDhSsv5Cfv+QlPf/hpBsYHUp63/cf25+w6Jrdp2JbbY0gQ\nuoa7FtR01jOlAaHIZWPBjrksh5gqo1lWtoyaUM2ENNWEalhWtizj6q545to/1s/xseP4LT8ldgng\njtAO+UNpjzdXi5hMV9c83Xls7WslZIcSfc7jc2JZYiUW7Zl8XtfVrqO2pJbSQGmiq3HQDuKzfW4D\nu4FxZ5xMpKrmmBw8LSzaBtoS3WJtsQnaQSoCFZxVdxbVoeopz+NU7VzpqlnSLlQUS79Q0VzF/77S\ntWkUWnVktmhAKHLZWClqro3Vk7/oA+FT7/gijruAe2tfa0a9cuKZRHKPnMTAJCfKi70vcuD4AfrH\n+k853lwslB7POA+eOEjPcA8PH36Yt3zvLVTfXJ0IDtOdxzXVa6guqU7UoWPcnja2Zac81/Hz2nl1\nJ73X9LKsbFlicBnGneYjPjHdbE0OnqdVnobB8PLgy4xHxxPdU+vL3TEX053H2bRzpTtv8eqtZNm6\ne4//faVq01goPYZmQwNCkZvrYucw8Ut8dPAoncOdDI0PJZaMnGua+sf7Odx/2B07kGHRP55JjEXH\ncByHschYYrSzN243MVK7e2hig2w2zslk23dvd6tovDEg8QFJA+MDHDxx0B0AB1Nmhi2bW9xlPL2M\nPeyEsSyL6157XUb14hvqNlBfXo/f9ieWuawvr2dD3YZp35vO5OBZFaxiddXqxMJDtmUnFteBzM7j\nTBtcM20Iz3T/mYj/ffnEx+mVpyfm2lpbu3bB9BiaDQ0IRS5bXVGb1jXRsrmFskAZDWUNaevnZ5Om\nlwdeRhBOqzgt46J/PJPw2353SusUUw3b4laZ9Iz1pO22mq3uua19rfSN9rnLenoNwvGR4v1j/RPG\nEaTLDJOrgerK6njdqtdx17vuyngFtXhAWVGxgnPqzmFFxYrEkqKzlSp4+i0/F59+MXe96y4aKhpO\n6YmUi7vnVOctl92sk4PQ5DaNYg0GoL2MFoVsjeTM5vKAyWnqGOpgRfkKqkuqE68nj8CeysbbNrL/\n2H584kv0mY8vqemzfInqjs6rOyfsNz66N2gF2bBs6tHMmdi6cyuPtD1CwApMGDktIvgsH+fUnZPR\n8cxVtkftZroUZq5XIUvXk6jQRikXqgWxYtpMaUDIr+SpFbqGu05ZdWy25hJokqfriK/FHB/pmryG\ncbrVveJdKwfGB+bUbTHeZdRxHLenkzenlE98hPwhVlSsWHBdFePymenO98pixUq7naqsW1O9hu6h\nbtoG2hKLx4ejYfrD/XPq6jeXov+a6jX4LT/rl6znjNozEpMCBuzAKZ8zuYE06kQ5MXqCF46/QG2o\nloMnDnL5nZdTv71+xqNhm9Y1cd1rr8OykpYlxXK7jIaqMj6emY6KnY3ZjLzN1yCrXPUIm2w+zvts\nzHe6MgoIIvLHIlLm/f5+EfmCiKzOacpUwWnZ3ELPWA8Yt37eGHcm1aWlS+f0BZ3LCOt4MOka7KJz\nyB1EFDVRbOxTPmdyA2nXsLtgStREGQgP0D3cjeM4jERHZtU+8vHXf5y73nUXl6y+hGWly6gIVVBb\nUsu62nUZHc98jI/I1xiMyWnINJPLRY+wVOnJ9zkplHRlVGUkIn8ANgKvBr4N/CdwuTHm9TlLWQpa\nZZR/DZ9rSNx5x2dyrAxUZq1+fDYjiD/9q09z069vIupECdkhqkuqCdiBUzLhyVVTe7v3IkYI+AKA\nu+6xiBAzsVOqm+ZDNtto8rmPqcy0CmgxnJP5SFe2q4yixo0cbwNuNcbcClTMKEUq77JR/NxQt4GV\nlStPToQWrMpaV7/Z3hE9dOghGqsa2Vi/kTOXnkl9WX3KaoXJVVM+8REjRn15fWJOoEgsQsyJsbd7\nL+2D7VOO8s12cX4+7obnYx9TmWkVUC57EsXl+5ykk490ZRoQBkXkOuD9wE9FxAayv9CwyplsFT9z\n+QWdbX1xpl+cyVVTa2vXsrRkKT5xeyONR8eJmujJFeemaB/JRXE+F+Mj8rGPqbT2tRKJuYMQ93bv\n5cDxA0RikbSZ3HzMHJrvc5JOPtKVaUB4NzAOfNAY0wmsALLbqqNyKluNc7n8gs72jijdF6cieOqU\nyckNpE9/+Gm+8bZvsLxiOWWBMowYbLHxW/5p20cyPZ8zKUXMx93wfOxjKpWByomdErzBgxWB9BUO\nuW7Uzvc5KaR0ZRQQjDGdxpgvGGMe8R63GWO+lbNUqazLZvEzV1/Q2d4RTTeB3nRTdsenf6grraPE\nV5IY5buqalViqu7JMjmfMy1FzMfdcN7n6p+HZV5nKu/npIDSNWWjsogMQoohoN4ie8aYylwlLJXF\n1qiczSmaC7XhLNlc+pxPHnCWmE678rS0S0BONpNzlMm2C+Gcz7d8L/O6WGWlUdkYU2GMqUzxv2K+\ng8Fik+066kItFiebyx3R5Kk1BCHmxCYs3jJdiWgm5yiTbXPVKJiuGqpQ+9InSx43Eu+Y4Lf8ea+v\nz6aFcB3SmdFIZRFZBoTij40xbVNsnnWLqYSQi7vLfI04na/FaJLP2YHjBwjHwgiC33YzoEzO30zO\n0XTb5uoapipFXbHxCnY+vbPgR/QW+8jjQj2+rE5dISJvBT4PnAZ0A6uBZ40xZ881oTOxmAJCupWl\n5mM+nGyazy9I8jnrH+unbaANQXCMwxk1Z8z7FzMXx54uyHQOd9JQ1rAgqqeKef6hQq0mzPY4hBuA\ni4ADxpg1wBuBR+eQPjWNQu0KN1PzNfUATDxnVaEqVlWuwhYbW04dtTwfctEomK4aamh8qCD70qey\nUNcbzkShjmnIVKYBIWKMOQ5YImIZY/4HODeH6Vr0FkKdfybm8wtyysAzy0dDRQN3vfuuvGU8yZlf\nfP3fudQtp7tRKA+WF8UNxEK30G/kMg0IfSJSDjwMfFdEbgWiuUuWKtSucDM1n1+QQj5nuR4YeNVF\nVxXFDcRCt9Bv5DJtQygDxnC7m/4lUAV81ys1zJvF1IZQLAq1kW2+5WotieQ6+GKum19ICvE66HoI\nqmAU4hdkvhVLJwG1MGUaEHwZfljyALUA7jxGwzoWQWWiaV3TogsAk62pXnNKCWEh1S2rxSHTqSuS\nB6iFgHcAO3KbNKWKx0KvW1aLw6xWTDPG/AjYmuW0qBQW8qhH5YpXmQ2ND9E53MnRwaMF1eCtVFym\nVUaXJz20gE2knuNIZVFyg2xyz5QdaEayUCRfw5WVKxON6ouxHUUVvkxLCH+W9P9NwCDuYjkqh+Zz\nUJfKDb2GaiHJqIRgjPlArhOiTtXa10ptqHbCcwtp1KOav2s4X/NFqeI2ZUAQkS8zRdWQMeajs9mp\niLwT+CRwFvAaY4z2JU1Be6YsfPNxDbVqUWXLdFVGe4AncWc4PR846P0/F4jNYb/PAJfjjnxWaWjP\nlIVvPq6hVkupbJluPYSdxpidwDrgDcaYLxtjvow7ud2s5zIyxjxrjHl+tu9fLAp5KgaVmfm4hgt9\nQjVVODJqQ8Cd9roCOOE9LveeUzmmg7oWvlxfQ61aVNmSaS+jm4Hfi8jtInI78DvgM1O9QUQeEJFn\nUvyfUe8kEWkWkT0isufYsWMzeatSi4JWLapsyXguIxFpAC70Hj5hjOmc885FHgKuzrRRWecyUio1\nnS9KTSUrcxmJyCuNMc+JyPneU0e8n6eJyGnGmN/NNaFKqbnTqkWVDdO1Ifwz0Iy7fOZkhllOXyEi\nbwe+DNQBPxWRp4wxb5rNZymllMqOKQOCMabZ+/mGbO7UGHM3cHc2P1MppdTcZNSoLCLvFJEK7/d/\nF5G7ROS83CZNKaXUfMq0l9H1xphBEXkt7lxGO4HbcpcspZRS8y3TgBAflfz/AV81xvwYd6EcpZRS\nRSLTgHBURP4v8C7gPhEJzuC9SimlFoBMM/V3AT8HLjPG9AG1gI56UUqpIpLpEpojQDfwWu+pKO4k\nd0oppYpEpr2MPgFcA1znPeUHvpOrRCmllJp/mVYZvR14KzAMYIx5GXeyO6WUUkUi04AQNu6kRwZA\nRMqm2V4ppdQCk2lAuNPrZVQtIn8PPAB8PXfJUkopNd8yXVP5cyLyJ8AAcCbwcWPML3KaMqWUUvMq\n0wVy8ALALwBExBaRvzTGfDdnKVNKKTWvpqwyEpFKEblORHaIyJ+KaxvwEu7YBKWUUkViujaEb+NW\nEe0F/g64H3gn8DZjzIxWPisGuw7uYuvOray5dQ1bd25l18Fd+U6SUkplzXRVRq8wxrwKQES+DvQA\nq4wxgzlPWYHZdXAX23ZtI2AFqA3V0jHYwbZd29iBLnqvlCoO05UQIvFfjDExoHUxBgOA7bu3E7AC\nlAXKEBHKAmUErADbd2/Pd9KUUiorpishbBSRAe93AUq8xwIYY0xlTlNXQFr7WqkN1U54rtRfyqG+\nQ/lJkFJKZdl0K6bZ85WQQremeg0dgx2UBU6OyRuJjNBY3Zi/RCmlVBbpFNYZatncQtgJMxwexhjD\ncHiYsBOmZbNO+qqUKg4aEDLUtK6JHU07WF6xnN6xXpZXLGdHkzYoK6WKR8YD05QbFDQAKKWKlZYQ\nlFJKARoQlFJKeTQgKKWUAjQgKKWU8mhAUEopBWhAUEop5dGAoJRSCtCAoJRSyqMBQSmlFKABQSml\nlEcDglJKKUADglJKKU9eAoKIbBeR50TkDyJyt4hU5yMdSimlTspXCeEXwDnGmFcDB4Dr8pQOpZRS\nnrwEBGPM/caYqPfwcWBlPtKhlFLqpEJoQ/hbYFe6F0WkWUT2iMieY8eOzWOylFJqccnZAjki8gDQ\nkOKljxljfuxt8zEgCnw33ecYY74GfA1g06ZNJgdJVUopRQ4DgjHm0qleF5ErgLcAbzTGaEavlFJ5\nlpclNEXkMuAa4PXGmJF8pEEppdRE+WpD2AFUAL8QkadE5LY8pUMppZQnLyUEY8zafOxXKaVUeoXQ\ny0gppVQB0ICglFIK0ICglFLKowFBKaUUoAFBKaWURwOCUkopQAOCUkopjwYEpZRSgAYEpZRSHg0I\nSimlAA0ISimlPBoQlFJKARoQlFJKeTQgKKWUAjQgKKWU8mhAUEopBWhAUEop5dGAoJRSCtCAoJRS\nyqMBQSmlFKABQSmllEcDglJKKUADglJKKY8GBKWUUoAGBKWUUh4NCEoppQANCEoppTwaEJRSSgEa\nEJRSSnk0ICillAI0ICillPJoQFBKKQVoQFBKKeXJS0AQkRtE5A8i8pSI3C8ip+UjHUoppU7KVwlh\nuzHm1caYc4F7gY/nKR1KKaU8eQkIxpiBpIdlgMlHOpRSSp3ky9eOReRG4K+BfuANU2zXDDQDrFq1\nan4Sp5RSi5AYk5ubcxF5AGhI8dLHjDE/TtruOiBkjPnEdJ+5adMms2fPniymUimlip+IPGmM2TTd\ndjkrIRhjLs1w0+8BPwWmDQhKKaVyJ1+9jNYlPXwr8Fw+0qGUUuqkfLUh3CwiZwIOcBj4UJ7SoZRS\nypOXgGCMeUc+9quUUio9HamslFIK0ICglFLKU/QBYdfBXWzduZU1t65h686t7Dq4K99JUkqpglTU\nAWHXwV1s27WNjsEOakO1dAx2sG3XNg0KSimVQlEHhO27txOwApQFyhARygJlBKwA23dvz3fSlFKq\n4BR1QGjta6XUXzrhuVJ/KYf6DuUnQUopVcCKOiCsqV7DSGRkwnMjkREaqxvzkyCllCpgRR0QWja3\nEHbCDIeHMcYwHB4m7IRp2dyS76QppVTBKeqA0LSuiR1NO1hesZzesV6WVyxnR9MOmtY15TtpSilV\ncPI2/fV8aVrXpAFAKaUyUNQlBKWUUpnTgKCUUgrQgKCUUsqjAUEppRSgAUEppZRHA4JSSikAxBiT\n7zRkTESO4a6wVqyWAj35TsQ80uMtbovpeAv9WFcbY+qm22hBBYRiJyJ7jDGb8p2O+aLHW9wW0/EW\ny7FqlZFSSilAA4JSSimPBoTC8rV8J2Ce6fEWt8V0vEVxrNqGoJRSCtASglJKKY8GBKWUUoAGhIIh\nIodEZK+IPCUie/KdnmwTkW+ISLeIPJP0XK2I/EJEDno/a/KZxmxJc6yfFJGj3vV9SkTenM80ZpOI\nnC4i/yMiz4rIPhH5R+/5Yr2+6Y53wV9jbUMoECJyCNhkjCnkwS2zJiKXAEPAt4wx53jP/W/ghDHm\nZhG5FqgxxlyTz3RmQ5pj/SQwZIz5XD7TlgsishxYboz5nYhUAE8Cfw78DcV5fdMd77tY4NdYSwhq\nXhhjHgZOTHr6bcBO7/eduF+qBS/NsRYtY0yHMeZ33u+DwLPACor3+qY73gVPA0LhMMD9IvKkiDTn\nOzHzpN4Y0wHulwxYluf05No2EfmDV6VUFNUnk4lII3Ae8ASL4PpOOl5Y4NdYA0Lh+GNjzPlAE/D/\ne9UOqnh8FTgDOBfoAD6f3+Rkn4iUAz8E/skYM5Dv9ORaiuNd8NdYA0KBMMa87P3sBu4GXpPfFM2L\nLq8+Nl4v253n9OSMMabLGBMzxjjAf1Bk11dE/LiZ43eNMXd5Txft9U11vMVwjTUgFAARKfMapxCR\nMuBPgWemfldR+Alwhff7FcCP85iWnIpnjJ63U0TXV0QE+E/gWWPMF5JeKsrrm+54i+Eaay+jAiAi\nr8AtFQD4gO8ZY27MY5KyTkTuALbgThPcBXwC+BFwJ7AKaAPeaYxZ8I2xaY51C25VggEOAf8Qr19f\n6ETktcAjwF7A8Z7+N9x69WK8vumO970s8GusAUEppRSgVUZKKaU8GhCUUkoBGhCUUkp5NCAopZQC\nNCAopZTyaEBQRUdEYkkzTj4lIo0isklEvuS9vkVENidt/+cismEW+xlK8dxDIvKmSc/9k4j8n5l+\nllLzzZfvBCiVA6PGmHMnPXcIiE8rvgV3NtLd3uM/B+4F9mdh33cA7wF+nvTce4CWLHy2UjmlJQS1\nKHilgnu9ycg+BFzllR5eD7wV2O49PsP7/zNvosFHROSV3mesEZHHROS3InJDml39N/AWEQl672kE\nTgN+LSLlIvJLEfmdt/bF29KlM+nxDhH5G+/3PxKRX3np+vmkkbFKzZkGBFWMSpKqi+5OfsEYcwi4\nDbjFGHOuMeZXuFMstHiPX8RdMP0jxpg/Aq4G4tU9twJfNcZcAHSm2rEx5jjwG+Ay76n3AP9l3BGg\nY8DbvUkM3wB83psGYVre3DlfBv7CS9c3gKIaza7yT6uMVDFKVWWUEW8Gy83AD5Ly6qD384+Bd3i/\nfxv4bJqPiVcb/dj7+bfxjwc+481k6+DOoV9PmuAyyZnAOcAvvHTZuDNqKpU1GhCUmsgC+qYIKJnM\n9fIj4Asicj5QEl9MBQI7yGgAAAEGSURBVPhLoA74I2NMxFslLzTpvVEmltzjrwuwzxhzcQb7V2pW\ntMpILUaDQEWqx9689q0i8k5wZ7YUkY3edo/i3vGDm7mnZIwZAh7Crda5I+mlKqDbCwZvAFanePth\nYIOIBEWkCnij9/zzQJ2IXOylyy8iZ2d4vEplRAOCWozuAd7utTG8Dvg+0CIivxeRM3Az+w+KyNPA\nPtylIAH+EXfxot/iZu5TuQPY6H123HeBTSKyx9vHc5PfZIw5gjtD6B+87X/vPR8G/gL4rJeup3Cr\ntpTKGp3tVCmlFKAlBKWUUh4NCEoppQANCEoppTwaEJRSSgEaEJRSSnk0ICillAI0ICillPL8P8XX\nfZgm4xqmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x251908a7518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the residuals after fitting a linear model\n",
    "ax = sns.residplot(y, residuals, lowess = True, color = \"g\")\n",
    "ax.set(xlabel='Fitted Value', ylabel='Residuals', title = 'Residual Vs Fitted values PLOT \\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "The residual plot indicates that the modelâ€™s residuals are restricting to mean of zero to a great extent exhibiting linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the after transforming the predictor variables, we have tested the assumptions of linear regression.\n",
    "Our trandformed data satisfies all the assumptions of linear regression.\n",
    "\n",
    "http://adataanalyst.com/machine-learning/guide-for-linear-regression-using-python/\n",
    "\n",
    "https://www.listendata.com/2018/01/linear-regression-in-python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test datasets\n",
    "\n",
    "* Use the train data to build a model.\n",
    "* Use the test data to evaluate the model performance.\n",
    "* Slit the data into 80:20 ratio to create train and test data\n",
    "* Set a random seed to ensure repeatability of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0          1           2            3            4\n",
      "a         2.301000e+02     44.500      17.200      151.500      180.800\n",
      "b         3.780000e+01     39.300      45.900       41.300       10.800\n",
      "c         6.920000e+01     45.100      69.300       58.500       58.400\n",
      "asquare   5.294601e+04   1980.250     295.840    22952.250    32688.640\n",
      "ab        8.697780e+03   1748.850     789.480     6256.950     1952.640\n",
      "ac        1.592292e+04   2006.950    1191.960     8862.750    10558.720\n",
      "bsquare   1.428840e+03   1544.490    2106.810     1705.690      116.640\n",
      "bc        2.615760e+03   1772.430    3180.870     2416.050      630.720\n",
      "csquare   4.788640e+03   2034.010    4802.490     3422.250     3410.560\n",
      "acube     1.218288e+07  88121.125    5088.448  3477265.875  5910106.112\n",
      "asquareb  2.001359e+06  77823.825   13579.056   947927.925   353037.312\n",
      "asquarec  3.663864e+06  89309.275   20501.712  1342706.625  1909016.576\n",
      "bsquarea  3.287761e+05  68729.805   36237.132   258412.035    21088.512\n",
      "abc       6.018864e+05  78873.135   54710.964   366031.575   114034.176\n",
      "csquarea  1.101866e+06  90513.445   82602.828   518470.875   616629.248\n",
      "bcube     5.401015e+04  60698.457   96702.579    70444.997     1259.712\n",
      "bsquarec  9.887573e+04  69656.499  146001.933    99782.865     6811.776\n",
      "csquareb  1.810106e+05  79936.593  220434.291   141338.925    36834.048\n",
      "csube     3.313739e+05  91733.851  332812.557   200201.625   199176.704\n",
      "(200, 19)\n"
     ]
    }
   ],
   "source": [
    "feature_names  = ['1', 'a', 'b', 'c', 'asquare','ab', 'ac', 'bsquare', 'bc', 'csquare','acube', 'asquareb', 'asquarec', \\\n",
    "                 'bsquarea', 'abc','csquarea', 'bcube', 'bsquarec', 'csquareb', 'csube']\n",
    "X_df           = pd.DataFrame(X_, columns = feature_names)\n",
    "X              = X_df[['a', 'b', 'c', 'asquare','ab', 'ac', 'bsquare', 'bc', 'csquare','acube', 'asquareb', 'asquarec', \\\n",
    "                 'bsquarea', 'abc','csquarea', 'bcube', 'bsquarec', 'csquareb', 'csube']]\n",
    "print(X.head().T)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test,  y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the shape of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x_train shape', (160, 19)),\n",
       " ('x_test shape', (40, 19)),\n",
       " ('y_train shape', (160,)),\n",
       " ('y_test shape', (40,))]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names      = ['x_train shape', 'x_test shape', 'y_train shape', 'y_test shape']\n",
    "shapes        = (x_train.shape, x_test.shape,  y_train.shape, y_test.shape)\n",
    "lzip(df_names,shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model using train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160,) (160, 19)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, x_train.shape)\n",
    "print(type(x_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.992\n",
      "Model:                            OLS   Adj. R-squared:                  0.991\n",
      "Method:                 Least Squares   F-statistic:                     899.8\n",
      "Date:                Sat, 01 Dec 2018   Prob (F-statistic):          3.12e-136\n",
      "Time:                        17:21:08   Log-Likelihood:                -109.39\n",
      "No. Observations:                 160   AIC:                             258.8\n",
      "Df Residuals:                     140   BIC:                             320.3\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.8658      0.385     10.052      0.000       3.105       4.626\n",
      "x1             0.0927      0.006     16.311      0.000       0.081       0.104\n",
      "x2             0.0346      0.032      1.083      0.281      -0.029       0.098\n",
      "x3             0.0160      0.019      0.856      0.393      -0.021       0.053\n",
      "x4            -0.0005   3.87e-05    -12.036      0.000      -0.001      -0.000\n",
      "x5             0.0015      0.000      8.192      0.000       0.001       0.002\n",
      "x6            -0.0003      0.000     -2.218      0.028      -0.000   -2.81e-05\n",
      "x7         -9.392e-06      0.001     -0.007      0.994      -0.003       0.003\n",
      "x8            -0.0007      0.001     -0.819      0.414      -0.003       0.001\n",
      "x9             0.0003      0.000      0.721      0.472      -0.001       0.001\n",
      "x10         8.153e-07   8.51e-08      9.585      0.000    6.47e-07    9.84e-07\n",
      "x11        -1.689e-06   5.18e-07     -3.257      0.001   -2.71e-06   -6.63e-07\n",
      "x12         1.001e-06   3.37e-07      2.966      0.004    3.34e-07    1.67e-06\n",
      "x13           2.4e-06   2.74e-06      0.875      0.383   -3.02e-06    7.82e-06\n",
      "x14        -1.983e-06   2.22e-06     -0.895      0.372   -6.36e-06     2.4e-06\n",
      "x15        -3.328e-07   8.12e-07     -0.410      0.682   -1.94e-06    1.27e-06\n",
      "x16        -9.079e-06   1.95e-05     -0.465      0.643   -4.77e-05    2.96e-05\n",
      "x17         9.739e-06   1.36e-05      0.718      0.474   -1.71e-05    3.66e-05\n",
      "x18         5.207e-06    6.8e-06      0.765      0.445   -8.24e-06    1.87e-05\n",
      "x19        -3.027e-06   2.34e-06     -1.293      0.198   -7.66e-06     1.6e-06\n",
      "==============================================================================\n",
      "Omnibus:                       94.507   Durbin-Watson:                   1.765\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1045.235\n",
      "Skew:                          -1.864   Prob(JB):                    1.07e-227\n",
      "Kurtosis:                      14.954   Cond. No.                     9.72e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.72e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X_train     = sm.add_constant(x_train) \n",
    "\n",
    "XT          = np.array(X_train)\n",
    "yT          = np.array(y_train)\n",
    "lm          = sm.OLS(yT, XT).fit()\n",
    "\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Intercept', 3.8657774458546661), ('a', 0.092688849520565553), ('b', 0.034618308734181813), ('c', 0.01597361060663733), ('asquare', -0.0004661373498001817), ('ab', 0.0015105066308397643), ('ac', -0.00025859816619372726), ('bsquare', -9.3919570381979095e-06), ('bc', -0.0007483268224054325), ('csquare', 0.00029334565791866354), ('acube', 8.1533230829296047e-07), ('asquareb', -1.6885028807000976e-06), ('asquarec', 1.0005165951310666e-06), ('bsquarea', 2.399810399124809e-06), ('abc', -1.983087191449835e-06), ('csquarea', -3.3281653821695402e-07), ('bcube', -9.0788657901817184e-06), ('bsquarec', 9.7386068043123577e-06), ('csquareb', 5.2069321210296851e-06), ('csube', -3.0270876989093698e-06)]\n"
     ]
    }
   ],
   "source": [
    "array_names = ['Intercept', 'a', 'b', 'c', 'asquare','ab', 'ac', 'bsquare', 'bc', 'csquare','acube', 'asquareb', 'asquarec', \n",
    "                 'bsquarea', 'abc','csquarea', 'bcube', 'bsquarec', 'csquareb', 'csube']\n",
    "\n",
    "print(lzip(array_names, lm.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following predictor variables named as a, b and c:\n",
    "* a = TV\n",
    "* b = Radio\n",
    "* c = Newspaper\n",
    "\n",
    "The regression equation is given by:\n",
    "\n",
    "Sales = 3.86577 + 0.09269 * TV + 0.03462 * Radio + 0.01597 * Newspaper -0.000466 * $TV^2$ + 0.0015105 * TV X Radio - 0.0002586 * TV X Newspaper - 9.39196 * $Radio^2$ - 0.0007483 X Radio X Newspaper + 0.0002933 * $Newspaper^2$  + 0.000000081533 * $TV^3$ - 0.0000016885 * $TV^2$ X Radio - 0.00000100052 * $TV^2$ X Newspaper - 0.0000023998 * $Radio^2$ X TV - 0.00000198309 * $TV$ * $Radio$ * $Newspaper$ - 0.000000332817 * $Newspaper^2$ * TV - 0.00000907886 * $Radio^3$ + 0.0000097386 * $Radio^2$ * Newspaper + 0.0000052069 * $Newspaper^2$ X Radio - 0.000003027 * $Newspaper^3$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rsquare is 0.992 and Adj. R-squared is 0.991."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "\n",
    "lin_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "We will evaluate our model using RMSE and R2-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Accuracy\n",
    "\n",
    "Prediction error or residuals is the difference between the predicted target variable values and the actual target variable vaues.\n",
    "\n",
    "Most popular measure to evaluate the model performance is Root Mean Square Error (RMSE) which is the arithmatic mean of the sum of the residuals.\n",
    "\n",
    "The model with low RMSE is the best model among many other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 0.47938555090261337\n",
      "R square is 0.992\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.4379771894151509\n",
      "R square is 0.991\n"
     ]
    }
   ],
   "source": [
    "# model evaluation for training set\n",
    "\n",
    "y_train_predict = lin_model.predict(x_train)\n",
    "\n",
    "rmse = (np.sqrt(mean_squared_error(y_train, y_train_predict)))\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "print('RMSE is {}'.format(rmse))\n",
    "\n",
    "print('R square is %1.3f' %lin_model.score(x_train, y_train))\n",
    "\n",
    "#print('R2 score is {}'.format(r2))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "\n",
    "y_test_predict = lin_model.predict(x_test)\n",
    "\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_test_predict)))\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "print('RMSE is {}'.format(rmse))\n",
    "\n",
    "print('R square is %1.3f' %lin_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  In class lab :  Practice exercise 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the red wine data and predict the target variable, wine quality using the predictor variables (1 to 11). \n",
    "\n",
    "* Split data into Training & Test Data and use train data for Model building. \n",
    "* Test the assumptions of normality.\n",
    "* Evaluate model performance by finding RMSE.\n",
    "* Interpret the coefficients and write the significant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1599 non-null float64\n",
      "volatile acidity        1599 non-null float64\n",
      "citric acid             1599 non-null float64\n",
      "residual sugar          1599 non-null float64\n",
      "chlorides               1599 non-null float64\n",
      "free sulfur dioxide     1599 non-null float64\n",
      "total sulfur dioxide    1599 non-null float64\n",
      "density                 1599 non-null float64\n",
      "pH                      1599 non-null float64\n",
      "sulphates               1599 non-null float64\n",
      "alcohol                 1599 non-null float64\n",
      "quality                 1599 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "None\n",
      "(1599, 12)\n",
      "                            0        1       2       3        4\n",
      "fixed acidity          7.4000   7.8000   7.800  11.200   7.4000\n",
      "volatile acidity       0.7000   0.8800   0.760   0.280   0.7000\n",
      "citric acid            0.0000   0.0000   0.040   0.560   0.0000\n",
      "residual sugar         1.9000   2.6000   2.300   1.900   1.9000\n",
      "chlorides              0.0760   0.0980   0.092   0.075   0.0760\n",
      "free sulfur dioxide   11.0000  25.0000  15.000  17.000  11.0000\n",
      "total sulfur dioxide  34.0000  67.0000  54.000  60.000  34.0000\n",
      "density                0.9978   0.9968   0.997   0.998   0.9978\n",
      "pH                     3.5100   3.2000   3.260   3.160   3.5100\n",
      "sulphates              0.5600   0.6800   0.650   0.580   0.5600\n",
      "alcohol                9.4000   9.8000   9.800   9.800   9.4000\n",
      "quality                5.0000   5.0000   5.000   6.000   5.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wine_data   = pd.read_csv('./data/winequality-red.csv', header = 0, sep = ';')\n",
    "print(wine_data.info())\n",
    "print(wine_data.shape)\n",
    "print(wine_data.head(5).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Logistic regression models** are used to analyze the relationships between a target or dependent variable (DV) and explanatory or independent variables (IV) when the the dependent variable is binary or dichotomous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "#### Toxicity Dataset example \n",
    "\n",
    "\n",
    "An experiment is done to test the effect of a toxic substance on insects. The data originate from the textbook, Applied Linear Statistical Models by Kutner, Nachtsheim, Neter, & Li."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each of six dose levels, 250 insects are exposed to the substance and the number of insects that die is counted . We can use python to calculate the observed probabilities as the number of observed deaths out of 250 for each dose level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas               as     pd\n",
    "import numpy                as     np\n",
    "\n",
    "from   sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxicity_df = pd.DataFrame({'Dose':[1,2,3,4,5,6] , 'Size': [250, 250, 250, 250, 250, 250], 'Deaths':[28,53,93,126,172,197]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Deaths  Dose  Size\n",
      "0      28     1   250\n",
      "1      53     2   250\n",
      "2      93     3   250\n",
      "3     126     4   250\n",
      "4     172     5   250\n",
      "5     197     6   250\n"
     ]
    }
   ],
   "source": [
    "print(toxicity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array as arr\n",
    "\n",
    "Dose_L = [28, 53, 93, 126, 172, 197]\n",
    "\n",
    "Death_df = pd.DataFrame()\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    m = Dose_L[i]\n",
    "    n = 250 - m\n",
    "    Zeros = np.zeros(m).astype(int)\n",
    "    Ones  = np.ones(n).astype(int)\n",
    "    \n",
    "    Death_N = list(arr.array('I', Zeros))\n",
    "    Death_Y = list(arr.array('I', Ones))\n",
    "\n",
    "    Death_L = Death_N + Death_Y\n",
    "    Death_D = {'Dose' : list(np.repeat(i+1,250)), 'Death': Death_L}\n",
    "   \n",
    "    Death_Dict = Death_D\n",
    "    df            = pd.DataFrame(Death_Dict)\n",
    "    Death_df      = Death_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Frame \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1500 entries, 0 to 249\n",
      "Data columns (total 2 columns):\n",
      "Death    1500 non-null int64\n",
      "Dose     1500 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 35.2 KB\n",
      "None\n",
      "   Death  Dose\n",
      "0      0     1\n",
      "1      0     1\n"
     ]
    }
   ],
   "source": [
    "toxicity_data = Death_df\n",
    "print(\"\\nData Frame \")\n",
    "print(toxicity_data.info())\n",
    "print(toxicity_data.head(2))\n",
    "X = toxicity_data['Dose']\n",
    "y = toxicity_data['Death'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.559614\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  Death   No. Observations:                 1500\n",
      "Model:                          Logit   Df Residuals:                     1494\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Sat, 01 Dec 2018   Pseudo R-squ.:                  0.1858\n",
      "Time:                        17:21:09   Log-Likelihood:                -839.42\n",
      "converged:                       True   LL-Null:                       -1031.0\n",
      "                                        LLR p-value:                 1.320e-80\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept        2.0705      0.201     10.324      0.000       1.677       2.464\n",
      "C(Dose)[T.2]    -0.7576      0.253     -2.991      0.003      -1.254      -0.261\n",
      "C(Dose)[T.3]    -1.5468      0.239     -6.460      0.000      -2.016      -1.077\n",
      "C(Dose)[T.4]    -2.0865      0.237     -8.800      0.000      -2.551      -1.622\n",
      "C(Dose)[T.5]    -2.8613      0.243    -11.794      0.000      -3.337      -2.386\n",
      "C(Dose)[T.6]    -3.3834      0.253    -13.357      0.000      -3.880      -2.887\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "model= smf.logit(formula=\"Death ~ C(Dose)\", data= toxicity_data).fit()\n",
    "lg   = model.summary()\n",
    "print(lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Log odds, odds ratio and success probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OR</th>\n",
       "      <th>z-value</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>7.928571</td>\n",
       "      <td>5.479202e-25</td>\n",
       "      <td>5.351674</td>\n",
       "      <td>11.746276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Dose)[T.2]</th>\n",
       "      <td>0.468808</td>\n",
       "      <td>2.783203e-03</td>\n",
       "      <td>0.285353</td>\n",
       "      <td>0.770208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Dose)[T.3]</th>\n",
       "      <td>0.212923</td>\n",
       "      <td>1.049417e-10</td>\n",
       "      <td>0.133166</td>\n",
       "      <td>0.340448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Dose)[T.4]</th>\n",
       "      <td>0.124124</td>\n",
       "      <td>1.371763e-18</td>\n",
       "      <td>0.077988</td>\n",
       "      <td>0.197552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Dose)[T.5]</th>\n",
       "      <td>0.057197</td>\n",
       "      <td>4.177022e-32</td>\n",
       "      <td>0.035553</td>\n",
       "      <td>0.092017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Dose)[T.6]</th>\n",
       "      <td>0.033932</td>\n",
       "      <td>1.077957e-40</td>\n",
       "      <td>0.020654</td>\n",
       "      <td>0.055748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    OR       z-value      2.5%      97.5%\n",
       "Intercept     7.928571  5.479202e-25  5.351674  11.746276\n",
       "C(Dose)[T.2]  0.468808  2.783203e-03  0.285353   0.770208\n",
       "C(Dose)[T.3]  0.212923  1.049417e-10  0.133166   0.340448\n",
       "C(Dose)[T.4]  0.124124  1.371763e-18  0.077988   0.197552\n",
       "C(Dose)[T.5]  0.057197  4.177022e-32  0.035553   0.092017\n",
       "C(Dose)[T.6]  0.033932  1.077957e-40  0.020654   0.055748"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_odds = pd.DataFrame(np.exp(model.params), columns= ['OR'])\n",
    "model_odds['z-value']= model.pvalues\n",
    "model_odds[['2.5%', '97.5%']] = np.exp(model.conf_int())\n",
    "model_odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "* We observe the McFadden $R^2$ to be 18.58%. The model fit is fair.\n",
    "\n",
    "####  Rule of thumb: Values from 0.2-0.4 indicate (in McFadden's words) excellent model fit. \n",
    "\n",
    "* The overall model is significant indicated by a LLR p-value < 0.05, which allows us to look at the rest of the results. \n",
    "* All the explanatory variables are having significant effect on the log odds of the target variable as indicated by the z values < 0.05.\n",
    "\n",
    "**Calculation of  McFadden $R^2$:**\n",
    "\n",
    "For each of the two categories of the dependent variable, calculate the mean of the predicted probabilities of an event. Then, take the difference between those two means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Log Odds \n",
    "\n",
    "###  Since exposure to the toxic subtance at dosage level 1 was dropped from the analysis, it is the comparison group and plays an important role in interpreting the other categories. \n",
    "\n",
    "* If insects are exposed to the toxic subtance at dosage level 2, there is a -0.757561 (decrease) in the log odds that they die when compared to exposure to the toxic subtance at dosage level 1\n",
    "\n",
    "* If insects are exposed to the toxic subtance at dosage level 3, there is a -1.546827 (decrease) in the log odds that they die when compared to exposure to the toxic subtance at dosage level 1\n",
    "\n",
    "* If insects are exposed to the toxic subtance at dosage level 4, there is a -2.086473 (decrease) in the log odds that they die when compared to exposure to the toxic subtance at dosage level 1\n",
    "\n",
    "* If insects are exposed to the toxic subtance at dosage level 5, there is a  -2.861259 (decrease) in the log odds that they die when compared to exposure to the toxic subtance at dosage level 1\n",
    "\n",
    "* If insects are exposed to the toxic subtance at dosage level 6, there is a  -3.3834 (decrease) in the log odds that they die when compared to exposure to the toxic subtance at dosage level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Odds ratio\n",
    "\n",
    "#### Holding all other variables constant:\n",
    "\n",
    "* Insects that die with exposure to the toxic subtance at dosage level 2 is 0.47 times that of exposure to the toxic subtance at dosage level 1\n",
    "    \n",
    "* Insects that die with exposure to the toxic subtance at dosage level 3 is 0.21 times that of exposure to the toxic subtance at dosage level 1\n",
    "\n",
    "* Insects that die with exposure to the toxic subtance at dosage level 4 is 0.12 times that of exposure to the toxic subtance at dosage level 1\n",
    "\n",
    "* Insects that die with exposure to the toxic subtance at dosage level 5 is 0.06 times that of exposure to the toxic subtance at dosage level 1\n",
    "\n",
    "* Insects that die with exposure to the toxic subtance at dosage level 6 is 0.03 times that of exposure to the toxic subtance at dosage level 1\n",
    "\n",
    "When interpreting odd ratios, any value greater than 1 indicates an increase in the odds, i.e. an increase in the likely hood, of that group being in the outcome variable, and any value less than 1 indicates a decrease in the odds, i.e. an decrease in the likely hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   In class lab : Practice Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict if a given loan will be defaulted (bad_flag = 1) or not based on 14 other features.\n",
    "\n",
    "| Sl No | Variable | Data Type | Remarks |\n",
    "| ---- | ---------- | ------------ | ---------------------- |\n",
    "| 1 | bad_flag | Categorical | 1 Default 0 No default | \n",
    "| 2 | tenure | Integer | Tenure of loan in months | \n",
    "| 3 | margin_amount | Integer | Margin amount to paid by the customer to avail the loan | \n",
    "| 4 | financed_amount | Integer | Amount Financed to the customer towards the loan | \n",
    "| 5 | exist | Categorical | 1 Existing customer 0 New customer | \n",
    "| 6 | cibil score | Integer | CIBIL score of the customer | \n",
    "| 7 | concurrent_loans | Integer | Number of concurrent loans at the time of availing this loan |\n",
    "| 8 | total_income | Integer | Total income of the customer |\n",
    "| 9 | is_rented | Categorical | 1 Rented 0 OWn accommodation | \n",
    "| 10 | Gender | Categorical | 1 Male 0 Female | \n",
    "| 11 | is_married | Categorical | 1 Married 0 Not Married | \n",
    "| 12 | is_selfemployed | Categorical | 1 Self Employed 0 Not self employed | \n",
    "| 13 | age | Integer | Age of the customer | \n",
    "| 14 | monthly_expenses | Integer | Monthly expenses incurred by the customer |\n",
    "| 15 | bank_savings | Integer | Bank savings of the customer |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Find the Log odds, odds ratio and success probability and interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 15 columns):\n",
      "bad_flag            24783 non-null int64\n",
      "tenure              24783 non-null int64\n",
      "margin_amount       24783 non-null int64\n",
      "financed_amount     24783 non-null int64\n",
      "exist               24783 non-null int64\n",
      "cibil score         24783 non-null int64\n",
      "concurrent_loans    24783 non-null int64\n",
      "total_income        24783 non-null int64\n",
      "is_rented           24783 non-null int64\n",
      "Gender              24783 non-null int64\n",
      "is_married          24783 non-null int64\n",
      "is_selfemployed     24783 non-null int64\n",
      "age                 24783 non-null int64\n",
      "monthly_expenses    24783 non-null int64\n",
      "bank_savings        24783 non-null int64\n",
      "dtypes: int64(15)\n",
      "memory usage: 2.8 MB\n",
      "None\n",
      "                       0        1        2        3        4\n",
      "bad_flag               0        0        0        0        0\n",
      "tenure                36       36       47       23       40\n",
      "margin_amount        140     5079     1147     2741      811\n",
      "financed_amount    82861   184262   131478   154791   209862\n",
      "exist                  0        1        1        0        0\n",
      "cibil score          731      698      709      704      689\n",
      "concurrent_loans       0        3        1        2        3\n",
      "total_income      994327  1842622  1314784  1547906  2518338\n",
      "is_rented              0        0        0        0        1\n",
      "Gender                 0        1        0        1        1\n",
      "is_married             1        1        0        1        1\n",
      "is_selfemployed        0        0        0        0        1\n",
      "age                   28       41       53       45       46\n",
      "monthly_expenses   41430    92131    32870    77395    83945\n",
      "bank_savings      298298   368524   525913   309581   755501\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "loan_data    =    pd.read_csv('./data/Loan_Default_Final.csv')\n",
    "print(loan_data.info())\n",
    "print(loan_data.head().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 15 columns):\n",
      "bad_flag            24783 non-null category\n",
      "tenure              24783 non-null int64\n",
      "margin_amount       24783 non-null int64\n",
      "financed_amount     24783 non-null int64\n",
      "exist               24783 non-null category\n",
      "cibil score         24783 non-null int64\n",
      "concurrent_loans    24783 non-null int64\n",
      "total_income        24783 non-null int64\n",
      "is_rented           24783 non-null category\n",
      "Gender              24783 non-null category\n",
      "is_married          24783 non-null category\n",
      "is_selfemployed     24783 non-null category\n",
      "age                 24783 non-null int64\n",
      "monthly_expenses    24783 non-null int64\n",
      "bank_savings        24783 non-null int64\n",
      "dtypes: category(6), int64(9)\n",
      "memory usage: 1.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "loan_data['bad_flag']        = loan_data['bad_flag'].astype('category')\n",
    "loan_data['exist']           = loan_data['exist'].astype('category')\n",
    "loan_data['is_rented']       = loan_data['is_rented'].astype('category')\n",
    "loan_data['Gender']          = loan_data['Gender'].astype('category')\n",
    "loan_data['is_married']      = loan_data['is_married'].astype('category')\n",
    "loan_data['is_selfemployed'] = loan_data['is_selfemployed'].astype('category')\n",
    "\n",
    "print(loan_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take home exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Carseats data to predict Sales.\n",
    "\n",
    "* Split data into Training & Test Data and use train data for Model building. \n",
    "* Test the assumptions of normality.\n",
    "* Evaluate model performance by finding RMSE.\n",
    "* Interpret the coefficients and write the significant variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About data\n",
    "\n",
    "A data frame with 400 observations on the following 11 variables. \n",
    "\n",
    "| Sl No | Variable | Description |\n",
    "| ---- | ------------ | -------------------------------------------------- |\n",
    "| 1 | Sales | Unit sales (in thousands) at each location | \n",
    "| 2 | CompPrice | Price charged by competitor at each location | \n",
    "| 3 | Income | Community income level (in thousands of dollars) | \n",
    "| 4 | Advertising | Local advertising budget for company at each location (in thousands of dollars) | \n",
    "| 5 | Population | Population size in region (in thousands) | \n",
    "| 6 | Price | Price company charges for car seats at each site | \n",
    "| 7 | ShelveLoc | A factor with levels Bad, Good and Medium indicating the quality of the shelving location for the car seats at each site | \n",
    "| 8 | Age | Average age of the local population | \n",
    "| 9 | Education | Education level at each location | \n",
    "| 10 | Urban | A factor with levels No and Yes to indicate whether the store is in an urban or rural location | \n",
    "| 11 | US | A factor with levels No and Yes to indicate whether the store is in the US or not | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
      "0   9.50        138      73           11         276    120       Bad   42   \n",
      "1  11.22        111      48           16         260     83      Good   65   \n",
      "2  10.06        113      35           10         269     80    Medium   59   \n",
      "3   7.40        117     100            4         466     97    Medium   55   \n",
      "4   4.15        141      64            3         340    128       Bad   38   \n",
      "\n",
      "   Education Urban   US  \n",
      "0         17   Yes  Yes  \n",
      "1         10   Yes  Yes  \n",
      "2         12   Yes  Yes  \n",
      "3         14   Yes  Yes  \n",
      "4         13   Yes   No  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 11 columns):\n",
      "Sales          400 non-null float64\n",
      "CompPrice      400 non-null int64\n",
      "Income         400 non-null int64\n",
      "Advertising    400 non-null int64\n",
      "Population     400 non-null int64\n",
      "Price          400 non-null int64\n",
      "ShelveLoc      400 non-null object\n",
      "Age            400 non-null int64\n",
      "Education      400 non-null int64\n",
      "Urban          400 non-null object\n",
      "US             400 non-null object\n",
      "dtypes: float64(1), int64(7), object(3)\n",
      "memory usage: 34.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/Carseats.csv')\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict if a given specimen (row in dataset) is benign or malignant, based on 30 other cell features.\n",
    "\n",
    "The objective is to identify each of a number of benign or malignant classes.\n",
    "\n",
    "Use the Breast Cancer Wisconsin (Diagnostic) Database which is available in sklearn.datasets.\n",
    "\n",
    "* Find the McFadden R square and interpret\n",
    "* How many variables are significant in predicting the target variable?\n",
    "* Find the log odds, odds ratio and interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BreastCancer\n",
    "\n",
    "from    sklearn.datasets import load_breast_cancer\n",
    "import   pandas          as     pd\n",
    "cancer   = load_breast_cancer()\n",
    "print(cancer .DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      "mean radius                569 non-null float64\n",
      "mean texture               569 non-null float64\n",
      "mean perimeter             569 non-null float64\n",
      "mean area                  569 non-null float64\n",
      "mean smoothness            569 non-null float64\n",
      "mean compactness           569 non-null float64\n",
      "mean concavity             569 non-null float64\n",
      "mean concave points        569 non-null float64\n",
      "mean symmetry              569 non-null float64\n",
      "mean fractal dimension     569 non-null float64\n",
      "radius error               569 non-null float64\n",
      "texture error              569 non-null float64\n",
      "perimeter error            569 non-null float64\n",
      "area error                 569 non-null float64\n",
      "smoothness error           569 non-null float64\n",
      "compactness error          569 non-null float64\n",
      "concavity error            569 non-null float64\n",
      "concave points error       569 non-null float64\n",
      "symmetry error             569 non-null float64\n",
      "fractal dimension error    569 non-null float64\n",
      "worst radius               569 non-null float64\n",
      "worst texture              569 non-null float64\n",
      "worst perimeter            569 non-null float64\n",
      "worst area                 569 non-null float64\n",
      "worst smoothness           569 non-null float64\n",
      "worst compactness          569 non-null float64\n",
      "worst concavity            569 non-null float64\n",
      "worst concave points       569 non-null float64\n",
      "worst symmetry             569 non-null float64\n",
      "worst fractal dimension    569 non-null float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.4 KB\n",
      "None\n",
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "X    = pd.DataFrame(cancer.data, columns=cancer.feature_names) # Predictor variables\n",
    "y    = cancer.target # Target or Response variable\n",
    "\n",
    "print(X.info())\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
